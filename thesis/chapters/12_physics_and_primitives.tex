\section{Physics Models and Algorithmic Primitives}

\subsection{Computation as Physics}

A central claim of this thesis is that computation is not merely an abstract mathematical process---it is a \textit{physical} process subject to physical laws. When a computer erases a bit, it dissipates heat. When it stores information, it consumes energy. The $\mu$-ledger tracks these physical costs.

To validate this connection, I develop explicit physics models within the Coq framework:
\begin{itemize}
    \item \textbf{Wave propagation}: A model of reversible dynamics with conservation laws
    \item \textbf{Dissipative systems}: A model of irreversible dynamics connecting to $\mu$-monotonicity
    \item \textbf{Discrete lattices}: A model of emergent spacetime from computational steps
\end{itemize}

These models are not metaphors---they are formally verified Coq proofs showing that computational structures exhibit physical-like behavior.
The wave model lives in \texttt{coq/physics/WaveModel.v}, and its embedding into the Thiele Machine is proven in \texttt{coq/thielemachine/coqproofs/WaveEmbedding.v}. The lattice and dissipative models follow the same pattern: define a state and step function, then prove conservation or monotonicity lemmas that can be linked back to kernel invariants.

\subsection{From Theory to Algorithms}

The second part of this chapter bridges the abstract theory to concrete algorithms. The Shor primitives demonstrate that the period-finding core of Shor's factoring algorithm can be formalized and verified in Coq, connecting:
\begin{itemize}
    \item Number theory (modular arithmetic, GCD)
    \item Computational complexity (polynomial vs.\ exponential)
    \item The Thiele Machine's $\mu$-cost model
\end{itemize}

This chapter documents the physics models that demonstrate emergent conservation laws and the algorithmic primitives that bridge abstract mathematics to concrete factorization.

\section{Physics Models}

The formal development contains verified physics models that demonstrate how physical laws emerge from computational structure.

\subsection{Wave Propagation Model}

Representative model: a 1D wave dynamics model with left- and right-moving amplitudes:
\begin{lstlisting}
Record WaveCell := {
  left_amp : nat;
  right_amp : nat
}.

Definition WaveState := list WaveCell.

Definition wave_step (s : WaveState) : WaveState :=
  let lefts := rotate_left (map left_amp s) in
  let rights := rotate_right (map right_amp s) in
  map2 (fun l r => {| left_amp := l; right_amp := r |}) lefts rights.
\end{lstlisting}

\textbf{Conservation theorems:}
\begin{lstlisting}
Theorem wave_energy_conserved : 
  forall s, wave_energy (wave_step s) = wave_energy s.

Theorem wave_momentum_conserved : 
  forall s, wave_momentum (wave_step s) = wave_momentum s.

Theorem wave_step_reversible : 
  forall s, wave_step_inv (wave_step s) = s.
\end{lstlisting}

These proofs demonstrate that even simple computational models exhibit physical-like conservation laws.
The key point is that the proofs are about the concrete \texttt{wave\_step} definition in the Coq file, not about an informal physical analogy. This is why the conservation laws can later be transported into kernel semantics via embedding lemmas.

\subsection{Dissipative Model}

The dissipative model captures irreversible dynamics, connecting to $\mu$-monotonicity of the kernel.

\subsection{Discrete Model}

The discrete model uses lattice-based dynamics for discrete spacetime emergence.

\section{Shor Primitives}

The formalization includes the mathematical foundations of Shor's factoring algorithm.

\subsection{Period Finding}

Representative definitions:
\begin{lstlisting}
Definition is_period (r : nat) : Prop :=
  r > 0 /\ forall k, pow_mod (k + r) = pow_mod k.

Definition minimal_period (r : nat) : Prop :=
  is_period r /\ forall r', is_period r' -> r' >= r.

Definition shor_candidate (r : nat) : nat :=
  let half := r / 2 in
  let term := Nat.pow a half in
  gcd_euclid (term - 1) N.
\end{lstlisting}

\textbf{The Shor Reduction Theorem:}
\begin{lstlisting}
Theorem shor_reduction :
  forall r,
    minimal_period r ->
    Nat.Even r ->
    let g := shor_candidate r in
    1 < g < N ->
    Nat.divide g N /\ 
    Nat.divide g (Nat.pow a (r / 2) - 1).
\end{lstlisting}

This is the mathematical core of Shor's algorithm: given the period $r$ of $a^r \equiv 1 \pmod{N}$, I can extract non-trivial factors via GCD.
These definitions and the theorem are formalized in \texttt{coq/shor\_primitives/PeriodFinding.v}, which provides the exact statements used in the proof scripts rather than an informal paraphrase.

\subsection{Verified Examples}

\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{N} & \textbf{a} & \textbf{Period r} & \textbf{Factors} & \textbf{Verification} \\
\hline
21 & 2 & 6 & 3, 7 & $2^3 = 8$; $\gcd(7, 21) = 7$ \\
15 & 2 & 4 & 3, 5 & $2^2 = 4$; $\gcd(3, 15) = 3$ \\
35 & 2 & 12 & 5, 7 & $2^6 = 64 \equiv 29$; $\gcd(28, 35) = 7$ \\
\hline
\end{tabular}
\end{center}

\subsection{Euclidean Algorithm}

Representative Euclidean algorithm:
\begin{lstlisting}
Fixpoint gcd_euclid (a b : nat) : nat :=
  match b with
  | 0 => a
  | S b' => gcd_euclid b (a mod (S b'))
  end.

Theorem gcd_euclid_divides_left : 
  forall a b, Nat.divide (gcd_euclid a b) a.

Theorem gcd_euclid_divides_right : 
  forall a b, Nat.divide (gcd_euclid a b) b.
\end{lstlisting}

\subsection{Modular Arithmetic}

Representative modular arithmetic lemma:
\begin{lstlisting}
Definition mod_pow (n base exp : nat) : nat := ...

Theorem mod_pow_mult : 
  forall n a b c, mod_pow n a (b + c) = ...
\end{lstlisting}

\section{Bridge Modules}

Bridge lemmas connect domain-specific constructs to kernel semantics via receipt channels.

\subsection{Randomness Bridge}

Representative bridge lemma:
\begin{lstlisting}
Definition RAND_TRIAL_OP : nat := 1001.

Definition RandChannel (r : Receipt) : bool :=
  Nat.eqb (r_op r) RAND_TRIAL_OP.

Lemma decode_is_filter_payloads :
  forall tr,
    decode RandChannel tr =
    map r_payload (filter RandChannel tr).
\end{lstlisting}

This bridge defines how randomness-relevant receipts are extracted from traces.
The formal statement above appears in \texttt{coq/bridge/Randomness\_to\_Kernel.v}. It is the connective tissue between high-level randomness claims and the kernel trace semantics, ensuring that a “randomness proof” is literally a filtered view of receipted steps.

Each bridge defines:
\begin{enumerate}
    \item A channel selector (opcode-based filtering)
    \item Payload extraction from matching receipts
    \item Decode lemmas proving filter-map equivalence
\end{enumerate}

\section{Flagship DI Randomness Track}

The project's flagship demonstration is \textbf{device-independent randomness} certification.

\subsection{Protocol Flow}

\begin{enumerate}
    \item \textbf{Transcript Generation}: decode receipts-only traces
    \item \textbf{Metric Computation}: compute $H_{\min}$ lower bound
    \item \textbf{Admissibility Check}: verify $K$-bounded structure addition
    \item \textbf{Bound Theorem}: $\text{Admissible}(K) \Rightarrow H_{\min} \le f(K)$
\end{enumerate}

\subsection{The Quantitative Bound}

Representative theorem:
\begin{lstlisting}
Theorem admissible_randomness_bound :
  forall K transcript,
    Admissible K transcript ->
    rng_metric transcript <= f K.
\end{lstlisting}

The bound $f(K)$ is explicit and quantitative---certified randomness is bounded by structure-addition budget.

\subsection{Conflict Chart}

The closed-work pipeline generates a comparison artifact:
\begin{itemize}
    \item Repo-measured $f(K)$ envelope
    \item Reference curve from standard DI theory
    \item Explicit assumption documentation
\end{itemize}

This creates an ``external confrontation artifact''---outsiders can disagree on assumptions but must engage with the explicit numbers.

\section{Theory of Everything Limits}

\subsection{What the Kernel Forces}

Representative theorem:
\begin{lstlisting}
Theorem KernelMaximalClosure : KernelMaximalClosureP.
\end{lstlisting}

The kernel forces:
\begin{itemize}
    \item No-signaling (locality)
    \item $\mu$-monotonicity (irreversibility accounting)
    \item Multi-step cone locality (causal structure)
\end{itemize}

\subsection{What the Kernel Cannot Force}

Representative theorem:
\begin{lstlisting}
Theorem CompositionalWeightFamily_Infinite :
  exists w : nat -> Weight,
    (forall k, weight_laws (w k)) /\
    (forall k1 k2, k1 <> k2 -> exists t, w k1 t <> w k2 t).
\end{lstlisting}

Infinitely many weight families satisfy compositionality---no unique probability measure is forced.

\begin{lstlisting}
Theorem Physics_Requires_Extra_Structure : KernelNoGoForTOE_P.
\end{lstlisting}

\textbf{Implication:} A unique physical theory cannot be derived from computational structure alone. Additional axioms (symmetry, coarse-graining, boundary conditions) are required.

\section{Complexity Comparison}

The Thiele Machine provides an alternative complexity model. The table below should be read as a qualitative comparison: time decreases as $\mu$ increases, not as a claim of universal asymptotic dominance.

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Algorithm} & \textbf{Classical} & \textbf{Thiele} \\
\hline
Integer factoring & Sub-exponential (classical) & Time traded for explicit $\mu$ cost \\
Period finding & $O(\sqrt{N})$ (classical) & Time traded for explicit $\mu$ cost \\
CHSH optimization & Brute force & Structure-aware \\
\hline
\end{tabular}
\end{center}

The key insight: Thiele Machine trades \textbf{blind search time} for \textbf{explicit structure cost} ($\mu$).

\section{Summary}

This chapter establishes:
\begin{enumerate}
    \item \textbf{Physics models}: Wave, dissipative, discrete dynamics with conservation laws
    \item \textbf{Shor primitives}: Period finding and factorization reduction, formally verified
    \item \textbf{Bridge modules}: domain-to-kernel bridges via receipt channels
    \item \textbf{Flagship track}: DI randomness with quantitative bounds
    \item \textbf{TOE limits}: No unique physics from compositionality alone
\end{enumerate}

The mathematical infrastructure supports both theoretical impossibility results and practical algorithmic applications.
