\section{Why Three Layers?}

\subsection{The Problem of Trust}

A formal specification proves properties but doesn't execute on real workloads. An executable implementation runs but might contain bugs or subtle semantic drift. How can I trust that the implementation matches the specification?

\textbf{Answer}: I build three independent implementations and verify they produce \textit{identical results} for all inputs. This makes the thesis rebuildable: every layer can be re-implemented from the definitions here, and any mismatch is detectable.
In practice, this means I can take a short instruction trace, run it through the Coq-extracted interpreter, the Python VM, and the RTL testbench, and compare the gate-appropriate observable projection. If any compared field diverges, I treat it as a semantic bug rather than a performance issue. That is the operational meaning of “trust” in this project.

\subsection{The Three Layers}

\begin{enumerate}
    \item \textbf{Coq (Formal)}: Defines ground-truth semantics. Every property is machine-checked. Extraction provides a reference evaluator.
    
    \item \textbf{Python (Reference)}: A human-readable implementation for debugging, tracing, and experimentation. Generates receipts and traces.
    
    \item \textbf{Verilog (Hardware)}: A synthesizable RTL implementation targeting real FPGAs. Proves the model is physically realizable.
\end{enumerate}
Concretely, the formal layer lives in \texttt{coq/kernel/*.v}, the Python reference VM is implemented under \texttt{thielecpu/} (notably \texttt{thielecpu/state.py} and \texttt{thielecpu/vm.py}), and the RTL is under \texttt{thielecpu/hardware/}. Keeping the directory layout explicit matters because it tells a reader exactly where to validate each part of the story.

\subsection{The Isomorphism Invariant}

For \textit{any} instruction trace $\tau$:
\[
S_{\text{Coq}}(\tau) = S_{\text{Python}}(\tau) = S_{\text{Verilog}}(\tau)
\]

This is not aspirational---it is enforced by automated tests. Any divergence is a critical bug, because it would mean at least one layer is not faithful to the formal semantics.
The tests compare \textit{state projections} rather than every internal variable. The projections are suite-specific: the compute gate in \texttt{tests/test\_rtl\_compute\_isomorphism.py} compares registers and memory, while the partition gate in \texttt{tests/test\_partition\_isomorphism\_minimal.py} compares canonicalized module regions from the partition graph. The extracted runner emits a full JSON snapshot (pc, $\mu$, err, regs, mem, CSRs, graph), but the RTL testbench exposes only the fields required by each gate.

\subsection{How to Read This Chapter}

This chapter is practical: it explains how the theory is instantiated in three concrete artifacts and how they are kept in lockstep.
\begin{itemize}
    \item Section 4.2: Coq formalization (state definitions, step relation, extraction)
    \item Section 4.3: Python VM (state class, partition operations, receipt generation)
    \item Section 4.4: Verilog RTL (CPU module, $\mu$-ALU, logic engine interface)
    \item Section 4.5: Isomorphism verification (how I test equality)
\end{itemize}

\textbf{Key concepts to understand}:
\begin{itemize}
    \item The \textbf{state record} shared across layers
    \item The \textbf{step relation} that advances state
    \item The \textbf{state projection} used for isomorphism tests
    \item The \textbf{receipt format} used for trace verification
\end{itemize}

\section{The 3-Layer Isomorphism Architecture}

The Thiele Machine is implemented across three layers that maintain strict semantic equivalence:
\begin{enumerate}
    \item \textbf{Formal Layer (Coq)}: Defines ground-truth semantics with machine-checked proofs
    \item \textbf{Reference Layer (Python)}: Executable specification with tracing and debugging
    \item \textbf{Physical Layer (Verilog)}: RTL implementation targeting FPGA/ASIC synthesis
\end{enumerate}

The central invariant is \textit{3-way isomorphism}: for any instruction sequence $\tau$, the final state projections chosen by the verification gates must be identical across all three layers. Those projections are observationally motivated and suite-specific (e.g., registers/memory for compute traces; module regions for partition traces), while the extracted runner provides a superset of observables that can be compared when a gate requires it.

\section{Layer 1: The Formal Kernel (Coq)}

\subsection{Structure of the Formal Kernel}

The formal kernel is organized around a small set of interlocking definitions:
\begin{itemize}
    \item \textbf{State and partition structure}: the record that defines registers, memory, the partition graph, and the $\mu$-ledger.
    \item \textbf{Step semantics}: the 18-instruction ISA and the inductive transition rules.
    \item \textbf{Logical certificates}: checkers for proofs and models that allow deterministic verification.
    \item \textbf{Conservation and locality}: theorems that enforce $\mu$-monotonicity and observational no-signaling.
    \item \textbf{Receipts and simulation}: trace formats and cross-layer correspondence lemmas.
\end{itemize}
These bullets correspond directly to files: \texttt{VMState.v} defines the state and partitions, \texttt{VMStep.v} defines the ISA and step relation, \texttt{CertCheck.v} defines certificate checkers, and conservation/locality theorems live in files such as \texttt{MuLedgerConservation.v} and \texttt{ObserverDerivation.v}. Receipts and simulation correspondences are defined in \texttt{ReceiptCore.v} and \texttt{SimulationProof.v}.

The goal is not to “encode” the implementation, but to define a minimal semantics from which every implementation can be reconstructed.

\subsection{The VMState Record}

The state is defined as a record with seven components:
\begin{lstlisting}
Record VMState := {
  vm_graph : PartitionGraph;
  vm_csrs : CSRState;
  vm_regs : list nat;
  vm_mem : list nat;
  vm_pc : nat;
  vm_mu : nat;
  vm_err : bool
}.
\end{lstlisting}

Each component has canonical width and representation:
\begin{itemize}
    \item \textbf{vm\_regs}: 32 registers (matching RISC-V convention)
    \item \textbf{vm\_mem}: 256 words of data memory
    \item \textbf{vm\_pc}: Program counter (modeled as a natural in proofs; masked to a fixed width in hardware)
    \item \textbf{vm\_mu}: $\mu$-ledger accumulator (modeled as a natural; exported at fixed width in hardware)
    \item \textbf{vm\_err}: Boolean error latch
\end{itemize}
In Coq, the register file and memory are lists, with indices masked by \texttt{reg\_index} and \texttt{mem\_index} in \texttt{coq/kernel/VMState.v}. This makes “out-of-range” indices deterministic and matches the fixed-width semantics of the RTL, where bit widths enforce modular addressing.

\subsection{The Partition Graph}

\begin{lstlisting}
Record PartitionGraph := {
  pg_next_id : ModuleID;
  pg_modules : list (ModuleID * ModuleState)
}.

Record ModuleState := {
  module_region : list nat;
  module_axioms : AxiomSet
}.
\end{lstlisting}

Key operations:
\begin{itemize}
    \item \texttt{graph\_pnew}: Create or find module for region
    \item \texttt{graph\_psplit}: Split module by predicate
    \item \texttt{graph\_pmerge}: Merge two disjoint modules
    \item \texttt{graph\_lookup}: Retrieve module by ID
    \item \texttt{graph\_add\_axiom}: Add logical constraint to module
\end{itemize}
In the Python reference VM (\texttt{thielecpu/state.py}), these same operations are implemented on a \texttt{RegionGraph} plus a parallel bitmask representation (\texttt{partition\_masks}) to make the RTL mapping explicit. The graph methods enforce the same disjointness and ID discipline as the Coq definitions so that the projection used for cross-layer checks is identical.

\subsection{The Step Relation}

The step relation is an inductive predicate with 18 constructors, one per opcode. Each constructor states the exact preconditions and the resulting next state:
\begin{lstlisting}
Inductive vm_step : VMState -> vm_instruction -> VMState -> Prop := 
| step_pnew : forall s region cost graph' mid,
    graph_pnew s.(vm_graph) region = (graph', mid) ->
    vm_step s (instr_pnew region cost)
      (advance_state s (instr_pnew region cost) graph' s.(vm_csrs) s.(vm_err))
| step_psplit : forall s m left right cost g' l' r',
    graph_psplit s.(vm_graph) m left right = Some (g', l', r') ->
    vm_step s (instr_psplit m left right cost)
      (advance_state s (instr_psplit m left right cost) g' s.(vm_csrs) s.(vm_err))
...
\end{lstlisting}

The \texttt{advance\_state} helper atomically updates PC and $\mu$:
\begin{lstlisting}
Definition advance_state (s : VMState) (instr : vm_instruction)
  (graph' : PartitionGraph) (csrs' : CSRState) (err' : bool) : VMState :=
  {| vm_graph := graph';
     vm_csrs := csrs';
     vm_regs := s.(vm_regs);
     vm_mem := s.(vm_mem);
     vm_pc := s.(vm_pc) + 1;
     vm_mu := apply_cost s instr;
     vm_err := err' |}.
\end{lstlisting}
The existence of \texttt{advance\_state\_rm} in \texttt{coq/kernel/VMStep.v} is equally important: register- and memory-modifying instructions (such as \texttt{XOR\_LOAD} and \texttt{XFER}) use a variant that updates \texttt{vm\_regs} and \texttt{vm\_mem} explicitly, so these updates are part of the inductive semantics rather than encoded as side effects.

\subsection{Extraction}

The formal definitions are extracted to a functional evaluator to create a reference semantics:
\begin{lstlisting}
Require Extraction.
Extraction Language OCaml.
Extract Inductive bool => "bool" ["true" "false"].
Extract Inductive nat => "int" ["0" "succ"].
...
Extraction "extracted/vm_kernel.ml" vm_step run_vm.
\end{lstlisting}

The extracted code compiles to a small runner, which serves as an oracle for Python/Verilog comparison.
The runner consumes traces and emits a JSON snapshot of the observable fields. This makes it possible to compare the extracted semantics to the Python VM and RTL without invoking Coq at runtime; the extraction step freezes the semantics into a standalone artifact.

\section{Layer 2: The Reference VM (Python)}

\subsection{Architecture Overview}

The reference VM is optimized for correctness and observability rather than performance. Its purpose is to be readable and to expose every state transition for inspection and replay.

\subsubsection{Core Components}

The reference VM is structured around:
\begin{itemize}
    \item \textbf{State}: a dataclass mirroring the formal record (registers, memory, CSRs, partition graph, $\mu$-ledger).
    \item \textbf{ISA decoding}: a compact representation of the 18 opcodes.
    \item \textbf{Partition operations}: creation, split, merge, and discovery.
    \item \textbf{Receipt generation}: cryptographic receipts for each step.
\end{itemize}

\subsubsection{The VM Class}

\begin{lstlisting}
class VM:
    state: State
    python_globals: Dict[str, Any] = None
    virtual_fs: VirtualFilesystem = field(default_factory=VirtualFilesystem)
    witness_state: WitnessState = field(default_factory=WitnessState)
    step_receipts: List[StepReceipt] = field(default_factory=list)

    def __post_init__(self):
        ensure_kernel_keys()
        if self.python_globals is None:
            globals_scope = {...}  # builtins + vm_* helpers
            self.python_globals = globals_scope
        else:
            self.python_globals.setdefault("vm_read_text", self.virtual_fs.read_text)
            ...
        self.witness_state = WitnessState()
        self.step_receipts = []
        self.register_file = [0] * 32
        self.data_memory = [0] * 256
\end{lstlisting}
The excerpt omits the full globals initialization for brevity, but it highlights the key fact: the VM owns a \texttt{State} object (mirroring the Coq record) and also keeps a minimal register file and scratch memory used by the XOR opcodes that map directly to RTL. This separation is intentional: the \texttt{State} captures the partition and $\mu$-ledger semantics, while the auxiliary arrays let the VM exercise hardware-style instructions without introducing a second, inconsistent notion of state.

\subsection{State Representation}

The reference state mirrors the formal definition, with explicit fields for the partition graph, axioms, control/status registers, and $\mu$-ledger:
\begin{lstlisting}
@dataclass
class State:
    mu_operational: float = 0.0
    mu_information: float = 0.0
    _next_id: int = 1
    regions: RegionGraph = field(default_factory=RegionGraph)
    axioms: Dict[ModuleId, List[str]] = field(default_factory=dict)
    csr: dict[CSR, int | str] = field(default_factory=...)
    step_count: int = 0
    mu_ledger: MuLedger = field(default_factory=MuLedger)
    partition_masks: Dict[ModuleId, PartitionMask] = field(default_factory=dict)
    program: List[Any] = field(default_factory=list)
\end{lstlisting}
The additional fields (\texttt{mu\_ledger}, \texttt{partition\_masks}, and \texttt{program}) are the bridge to the other layers. \texttt{mu\_ledger} makes the $\mu$-accounting explicit and provides a total used in cross-layer projections (the kernel’s \texttt{vm\_mu} in \texttt{coq/kernel/VMState.v} is a single accumulator). \texttt{partition\_masks} provides a compact, hardware-aligned encoding of regions. \texttt{program} aligns with \texttt{CoreSemantics.State.program} in \texttt{coq/thielemachine/coqproofs/CoreSemantics.v}, where the program is part of the executable state, even though the kernel’s \texttt{VMState} record itself does not carry a program field.

\subsection{The $\mu$-Ledger}

\begin{lstlisting}
@dataclass
class MuLedger:
    mu_discovery: int = 0   # Cost of partition discovery operations
    mu_execution: int = 0   # Cost of instruction execution
    
    @property
    def total(self) -> int:
        return self.mu_discovery + self.mu_execution
\end{lstlisting}

\subsection{Partition Operations}

\subsubsection{Bitmask Representation}

For hardware isomorphism, partitions use fixed-width bitmasks. This makes the partition representation stable, deterministic, and easy to compare across layers:
\begin{lstlisting}
MASK_WIDTH = 64  # Fixed width for hardware compatibility
MAX_MODULES = 8  # Maximum number of active modules

def mask_of_indices(indices: Set[int]) -> PartitionMask:
    mask = 0
    for idx in indices:
        if 0 <= idx < MASK_WIDTH:
            mask |= (1 << idx)
    return mask
\end{lstlisting}
The bitmask representation is the literal encoding used in the RTL, so the Python VM computes it alongside the higher-level \texttt{RegionGraph}. This dual representation is a safety check: if the set-based and bitmask-based views ever disagree, the VM can detect the mismatch before it propagates to hardware.

\subsubsection{Module Creation (PNEW)}

\begin{lstlisting}
def pnew(self, region: Set[int]) -> ModuleId:
    if self.num_modules >= MAX_MODULES:
        raise ValueError(f"Cannot create module: max modules reached")
    existing = self.regions.find(region)
    if existing is not None:
        return ModuleId(existing)
    mid = self._alloc(region, charge_discovery=True)
    self.axioms[mid] = []
    self._enforce_invariant()
    return mid
\end{lstlisting}
The first branch of \texttt{pnew} demonstrates the “idempotent discovery” rule: creating a module for a region that already exists returns the existing ID instead of duplicating it. This ensures that module IDs are stable across layers and that any $\mu$-cost charged for discovery is not accidentally paid twice.

\subsection{Sandboxed Python Execution}

The \texttt{PYEXEC} instruction executes user-supplied code. When sandboxing is enabled, execution is restricted to a safe builtins set and an AST allowlist. When sandboxing is disabled, the instruction behaves like a trusted host callback. The semantics are defined so that any side effects are observable in the trace, and any structural information revealed is charged in $\mu$.

\begin{lstlisting}
SAFE_IMPORTS = {"math", "json", "z3"}
SAFE_FUNCTIONS = {
    "abs", "all", "any", "bool", "divmod", "enumerate", 
    "float", "int", "len", "list", "max", "min", "pow",
    "print", "range", "round", "sorted", "sum", "tuple",
    "zip", "str", "set", "dict", "map", "filter",
    "vm_read_text", "vm_write_text", "vm_read_bytes",
    "vm_write_bytes", "vm_exists", "vm_listdir",
}
\end{lstlisting}

When sandboxing is enabled, the AST is validated before execution:
\begin{lstlisting}
SAFE_NODE_TYPES = {
    ast.Module, ast.FunctionDef, ast.ClassDef, ast.arguments,
    ast.arg, ast.Expr, ast.Assign, ast.AugAssign, ast.Name,
    ast.Load, ast.Store, ast.Constant, ast.BinOp, ast.UnaryOp,
    ast.BoolOp, ast.Compare, ast.If, ast.For, ast.While, ...
}
\end{lstlisting}

\subsection{Receipt Generation}

Every step generates a cryptographic receipt that records the pre-state, instruction, post-state, and observable evidence:
\begin{lstlisting}
def _record_receipt(self, step, pre_state, instruction):
    post_state, observation = self._simulate_witness_step(
        instruction, pre_state
    )
    receipt = StepReceipt.assemble(
        step, instruction, pre_state, post_state, observation
    )
    self.step_receipts.append(receipt)
    self.witness_state = post_state
\end{lstlisting}

\section{Layer 3: The Physical Core (Verilog)}

\subsection{Module Hierarchy}

The hardware implementation is organized into a CPU core, a $\mu$-accounting unit, a logic-engine interface, and a testbench. The hierarchy mirrors the formal model: the core executes the ISA, the accounting unit enforces $\mu$-monotonicity, and the logic interface brokers certificate checks. This makes the physical design a direct embodiment of the formal step relation.

\subsection{The Main CPU}

\begin{lstlisting}
module thiele_cpu (
    input wire clk,
    input wire rst_n,
    output wire [31:0] cert_addr,
    output wire [31:0] status,
    output wire [31:0] error_code,
    output wire [31:0] partition_ops,
    output wire [31:0] mdl_ops,
    output wire [31:0] info_gain,
    output wire [31:0] mu,  // $\mu$-cost accumulator
    output wire [31:0] mem_addr,
    output wire [31:0] mem_wdata,
    input wire [31:0] mem_rdata,
    output wire mem_we,
    output wire mem_en,
    ...
);
\end{lstlisting}

Key signals:
\begin{itemize}
    \item \textbf{mu}: The $\mu$-accumulator, exported for 3-way isomorphism verification
    \item \textbf{partition\_ops}: Counter for partition operations
    \item \textbf{info\_gain}: Information gain accumulator
    \item \textbf{cert\_addr}: Certificate address CSR
\end{itemize}

\subsection{State Machine}

The CPU uses a 10-state FSM:
\begin{lstlisting}
localparam [3:0] STATE_FETCH = 4'h0;
localparam [3:0] STATE_DECODE = 4'h1;
localparam [3:0] STATE_EXECUTE = 4'h2;
localparam [3:0] STATE_MEMORY = 4'h3;
localparam [3:0] STATE_LOGIC = 4'h4;
localparam [3:0] STATE_PYTHON = 4'h5;
localparam [3:0] STATE_COMPLETE = 4'h6;
localparam [3:0] STATE_ALU_WAIT = 4'h7;
localparam [3:0] STATE_ALU_WAIT2 = 4'h8;
localparam [3:0] STATE_RECEIPT_HOLD = 4'h9;
\end{lstlisting}

\subsection{Instruction Encoding}

Each 32-bit instruction is decoded into opcode and operands. The fixed-width encoding ensures that hardware and software agree on exact bit-level semantics:
\begin{lstlisting}
wire [7:0] opcode = current_instr[31:24];
wire [7:0] operand_a = current_instr[23:16];
wire [7:0] operand_b = current_instr[15:8];
wire [7:0] operand_cost = current_instr[7:0];
\end{lstlisting}

\subsection{$\mu$-Accumulator Updates}

Every instruction atomically updates the $\mu$-accumulator:
\begin{lstlisting}
OPCODE_PNEW: begin
    execute_pnew(operand_a, operand_b);
    // Coq semantics: vm_mu := s.vm_mu + instruction_cost
    mu_accumulator <= mu_accumulator + {24'h0, operand_cost};
    pc_reg <= pc_reg + 4;
    state <= STATE_FETCH;
end
\end{lstlisting}

\subsection{The $\mu$-ALU}

The $\mu$-ALU (\texttt{mu\_alu.v}) implements Q16.16 fixed-point arithmetic:
\begin{lstlisting}
module mu_alu (
    input wire clk,
    input wire rst_n,
    input wire [2:0] op,      // 0=add, 1=sub, 2=mul, 3=div, 4=log2, 5=info_gain
    input wire [31:0] operand_a,
    input wire [31:0] operand_b,
    input wire valid,
    output reg [31:0] result,
    output reg ready,
    output reg overflow
);

localparam Q16_ONE = 32'h00010000;  // 1.0 in Q16.16
\end{lstlisting}

The log2 computation uses a 256-entry LUT for bit-exact results:
\begin{lstlisting}
reg [31:0] log2_lut [0:255];
initial begin
    log2_lut[0] = 32'h00000000;
    log2_lut[1] = 32'h00000170;
    log2_lut[2] = 32'h000002DF;
    ...
end
\end{lstlisting}

\subsection{Logic Engine Interface}

The LEI (\texttt{lei.v}) connects to external Z3:
\begin{lstlisting}
module lei (
    input wire clk,
    input wire rst_n,
    input wire logic_req,
    input wire [31:0] logic_addr,
    output wire logic_ack,
    output wire [31:0] logic_data,
    output wire z3_req,
    output wire [31:0] z3_formula_addr,
    input wire z3_ack,
    input wire [31:0] z3_result,
    input wire z3_sat,
    input wire [31:0] z3_cert_hash,
    ...
);
\end{lstlisting}

\section{Isomorphism Verification}

\subsection{The Isomorphism Gate}

The 3-way isomorphism is verified by a test that:
\begin{enumerate}
    \item Generate instruction trace $\tau$
    \item Execute $\tau$ on Python VM $\rightarrow$ state $S_{\text{py}}$
    \item Execute $\tau$ on extracted runner $\rightarrow$ state $S_{\text{coq}}$
    \item Execute $\tau$ on Verilog sim $\rightarrow$ state $S_{\text{rtl}}$
    \item Assert $S_{\text{py}} = S_{\text{coq}} = S_{\text{rtl}}$
\end{enumerate}

\subsection{State Projection}

For comparison, states are projected to canonical summaries tailored to the gate being exercised. The extracted runner emits a full JSON snapshot (pc, $\mu$, err, regs, mem, CSRs, graph), which can be projected down to subsets. The compute gate uses only registers and memory, while the partition gate uses canonicalized module regions. A full projection helper is therefore a \emph{superset} view, not the only comparison performed:
\begin{lstlisting}
def project_state_full(state):
    return {
        "pc": state.pc,
        "mu": state.mu,
        "err": state.err,
        "regs": list(state.regs[:32]),
        "mem": list(state.mem[:256]),
        "csrs": state.csrs.to_dict(),
        "graph": state.graph.to_canonical(),
    }
\end{lstlisting}

\subsection{The Inquisitor}

The Inquisitor enforces the verification rules:
\begin{itemize}
    \item Scans the proof sources for \texttt{Admitted}, \texttt{admit.}, \texttt{Axiom}
    \item Verifies that the proof build completes successfully
    \item Runs isomorphism gates
    \item Reports HIGH/MEDIUM/LOW findings
\end{itemize}

The repository must have 0 HIGH findings to pass CI.

\section{Synthesis Results}

\subsection{FPGA Targeting}

The RTL can be synthesized for Xilinx 7-series FPGAs:
\begin{lstlisting}
$ yosys -p "read_verilog thiele_cpu.v; synth_xilinx -top thiele_cpu"
\end{lstlisting}

\subsection{Resource Utilization}

Under a reduced configuration (fewer modules, smaller regions):
\begin{itemize}
    \item NUM\_MODULES = 4
    \item REGION\_SIZE = 16
    \item Estimated LUTs: $\sim$2,500
    \item Estimated FFs: $\sim$1,200
\end{itemize}

Full configuration:
\begin{itemize}
    \item NUM\_MODULES = 64
    \item REGION\_SIZE = 1024
    \item Estimated LUTs: $\sim$45,000
    \item Estimated FFs: $\sim$35,000
\end{itemize}

\section{Toolchain}

\subsection{Verified Versions}

\begin{itemize}
    \item Coq 8.18.x (OCaml 4.14.x)
    \item Python 3.12.x
    \item Icarus Verilog 12.x
    \item Yosys 0.33+
\end{itemize}

\subsection{Build Commands}

\begin{lstlisting}
# Example commands (paths may vary by environment):
# - build the Coq kernel
# - run the two isomorphism tests
# - simulate the RTL testbench
# - run full synthesis when toolchains are installed
\end{lstlisting}

\section{Summary}

The 3-layer implementation ensures:
\begin{itemize}
    \item \textbf{Logical Certainty}: Coq proofs guarantee properties hold for all inputs
    \item \textbf{Operational Visibility}: Python traces expose every state transition
    \item \textbf{Physical Realizability}: Verilog synthesizes to real hardware
\end{itemize}

The binding across layers is not aspirational—it is enforced through automated isomorphism gates. The Inquisitor ensures that no admits, no axioms, and no semantic divergences are ever committed to the main branch.
