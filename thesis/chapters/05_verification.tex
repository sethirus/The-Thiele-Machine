%% ============================================================
%% Chapter 5 TikZ Diagrams
%% ============================================================

% Figure 1: Chapter 5 Roadmap
\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1.8, 
    node distance=2.5cm,
    block/.style={rectangle, draw, fill=blue!10, minimum width=5.4cm, minimum height=1.6cm, align=center},
    theorem/.style={rectangle, draw, fill=green!20, minimum width=5.0cm, minimum height=1.2cm, align=center, rounded corners},
    arrow/.style={->, >=stealth, thick}
]
    % Central node
    \node[block, fill=red!20, minimum width=7.2cm, align=center, text width=3.5cm] (zero) at (0,0) {\textbf{Zero-Admit Standard}\\No Admitted, No admit., No Axiom};
    
    % Top layer: State definitions
    \node[block, align=center, text width=3.5cm] (state) at (-4, 2) {State Definitions\\VMState, PartitionGraph};
    \node[block, align=center, text width=3.5cm] (step) at (0, 2) {Step Semantics\\vm\_step relation};
    \node[block, align=center, text width=3.5cm] (obs) at (4, 2) {Observables\\Observable, ObservableRegion};
    
    % Bottom layer: Theorems
    \node[theorem, align=center, text width=3.5cm] (nosig) at (-4.5, -2) {No-Signaling\\(\S5.4)};
    \node[theorem, align=center, text width=3.5cm] (mucons) at (-1.5, -2) {$\mu$-Conservation\\(\S5.4)};
    \node[theorem, align=center, text width=3.5cm] (nofi) at (1.5, -2) {No Free Insight\\(\S5.6)};
    \node[theorem, align=center, text width=3.5cm] (gauge) at (4.5, -2) {Gauge Invariance\\(\S5.4)};
    
    % Arrows from definitions to zero-admit
    \draw[arrow, shorten >=2pt, shorten <=2pt] (state) -- (zero);
    \draw[arrow, shorten >=2pt, shorten <=2pt] (step) -- (zero);
    \draw[arrow, shorten >=2pt, shorten <=2pt] (obs) -- (zero);
    
    % Arrows from zero-admit to theorems
    \draw[arrow, shorten >=2pt, shorten <=2pt] (zero) -- (nosig);
    \draw[arrow, shorten >=2pt, shorten <=2pt] (zero) -- (mucons);
    \draw[arrow, shorten >=2pt, shorten <=2pt] (zero) -- (nofi);
    \draw[arrow, shorten >=2pt, shorten <=2pt] (zero) -- (gauge);
    
    % Title
    \node at (0, 3.2) {\textbf{Chapter 5: Verification Architecture}};
\end{tikzpicture}
\caption{Chapter 5 roadmap: from definitions through zero-admit standard to theorems.}
\label{fig:ch5-roadmap}
\end{figure}

\paragraph{Understanding Figure \ref{fig:ch5-roadmap}:}

\textbf{Three layers (boxes):}
\begin{itemize}
    \item \textbf{Bottom: Definitions (blue)} - VMState, vm\_step foundational semantics
    \item \textbf{Middle: Zero-Admit Standard (orange)} - No Admitted/admit./Axiom enforcement
    \item \textbf{Top: Four theorems (green boxes)} - Observational no-signaling, Gauge invariance, $\mu$-conservation, No Free Insight
\end{itemize}

\textbf{Arrows:} Zero-admit standard feeds all four theorems - enforcement enables trust

\textbf{Key insight:} Verification pyramid - foundational definitions support strict standard which enables machine-checked theorems. All proven without admits.

\section{Why Formal Verification?}

\subsection{The Limits of Testing}

Testing can find bugs, but it cannot prove their absence. If you test a sorting algorithm on 1000 inputs, you have evidence it works on those 1000 inputs---but there are infinitely many possible inputs. Formal verification replaces empirical sampling with universal quantification.

\textbf{Formal verification} proves properties hold for \textit{all} inputs. When I prove "$\mu$ is monotonically non-decreasing," I don't test it on examples---I prove it mathematically.
In this project, “all inputs” means all possible states and instruction traces compatible with the formal semantics. The proofs quantify over arbitrary \texttt{VMState} values and instructions, not over a fixed test suite. This is why the proofs must be grounded in precise definitions: without the exact state and step definitions, a universal statement would be meaningless.

\subsection{The Coq Proof Assistant}

% Figure 7: Coq Verification Pipeline
\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1.8, 
    stage/.style={rectangle, draw, fill=blue!20, minimum width=4.6cm, minimum height=1.8cm, align=center, rounded corners},
    check/.style={rectangle, draw, fill=green!20, minimum width=4.0cm, minimum height=1.3cm, align=center, font=\footnotesize},
    arrow/.style={->, >=stealth, thick}
], node distance=2.5cm]
    % Pipeline stages
    \node[stage, align=center, text width=3.5cm] (def) at (0, 0) {Definitions\\VMState, vm\_step};
    \node[stage, align=center, text width=3.5cm] (spec) at (4, 0) {Specification\\Theorem stmt};
    \node[stage, align=center, text width=3.5cm] (proof) at (8, 0) {Proof\\Tactics};
    \node[stage, fill=green!30, align=center, text width=3.5cm] (qed) at (12, 0) {\textbf{Qed.}\\Verified};
    
    % Arrows
    \draw[arrow, shorten >=2pt, shorten <=2pt] (def) -- (spec);
    \draw[arrow, shorten >=2pt, shorten <=2pt] (spec) -- (proof);
    \draw[arrow, shorten >=2pt, shorten <=2pt] (proof) -- (qed);
    
    % Checks below
    \node[check] at (0, -1.5) {Type-checked};
    \node[check] at (4, -1.5) {Well-formed};
    \node[check] at (8, -1.5) {Complete};
    \node[check] at (12, -1.5) {Machine-verified};
    
    % Curry-Howard note
    \node[draw, fill=yellow!20, rounded corners, text width=10cm, align=center] at (6, -3) {
        \textbf{Curry-Howard Correspondence:}\\
        Types = Propositions, Programs = Proofs\\
        A Coq proof is a verified program that inhabits the theorem's type.
    };
\end{tikzpicture}
\caption{Coq verification pipeline: from definitions through proof to machine-verified Qed.}
\label{fig:coq-pipeline}
\end{figure}

\paragraph{Understanding Figure \ref{fig:coq-pipeline}:}

\textbf{Four pipeline stages (boxes):}
\begin{enumerate}
    \item \textbf{Definitions (blue):} VMState, vm\_step - type-checked foundations
    \item \textbf{Specification (blue):} Theorem statement - well-formed proposition
    \item \textbf{Proof (blue):} Tactics sequence - complete derivation
    \item \textbf{Qed. (green):} Machine-verified conclusion - permanently certified
\end{enumerate}

\textbf{Below each stage:} Validation checks - Type-checked, Well-formed, Complete, Machine-verified

\textbf{Bottom yellow box:} Curry-Howard Correspondence - Types = Propositions, Programs = Proofs. A Coq proof is a verified program inhabiting the theorem's type.

\textbf{Key insight:} Linear pipeline from definitions to Qed - each stage validated by Coq kernel. Once proven, permanently certain.

\paragraph{Coq is an interactive theorem prover} based on dependent type theory. A Coq proof is:
\begin{itemize}
    \item \textbf{Machine-checked}: The computer verifies every step
    \item \textbf{Constructive}: Proofs can be extracted to executable code
    \item \textbf{Permanent}: Once proven, the result is certain (assuming Coq's kernel is correct)
\end{itemize}
The guarantees come from the small, trusted kernel of Coq. Every lemma in the thesis is checked against that kernel, and extraction produces executable code whose behavior is justified by the same proofs. This matters because the extracted runner is used as an oracle in isomorphism tests; the proof context and the executable context are tied to the same semantics.

\subsection{Trusted Computing Base (TCB)}

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=\textbf{What Must Be Trusted}]
\textbf{The TCB for this thesis includes}:
\begin{enumerate}
    \item \textbf{Coq kernel} (8.18.x): The type-checker and proof-verification engine
    \item \textbf{Coq extraction correctness}: The OCaml code produced by extraction faithfully implements the semantics
    \item \textbf{Certificate checkers}: LRAT proof verifier and SAT model validator in \path{coq/kernel/CertCheck.v}
    \item \textbf{Hash primitives}: SHA-256 implementation for receipt chains (assumed collision-resistant)
    \item \textbf{Python interpreter}: CPython 3.12.x correctly implements Python semantics
    \item \textbf{Verilog simulator}: Icarus Verilog 12.x correctly simulates RTL behavior
    \item \textbf{Synthesis tools}: Yosys correctly translates Verilog to gate-level netlists (for FPGA claims)
\end{enumerate}

\textbf{What is NOT in the TCB}:
\begin{itemize}
    \item SMT solvers (Z3, CVC5): They can propose, but cannot force acceptance of false claims
    \item User-provided axioms: Soundness is "garbage in, garbage out"---false axioms yield false conclusions
    \item Unverified Python code outside the VM core
\end{itemize}
\end{tcolorbox}

\subsection{The Zero-Admit Standard}

The Thiele Machine uses an unusually strict standard:
\begin{itemize}
    \item \textbf{No \texttt{Admitted}}: Every theorem must be fully proven
    \item \textbf{No \texttt{admit.}}: No tactical shortcuts inside proofs
    \item \textbf{No \texttt{Axiom}}: No unproven assumptions (except foundational logic)
    \item \textbf{No vacuous statements}: All theorems prove meaningful properties, not trivial tautologies
\end{itemize}

This standard is enforced automatically. Any commit introducing an admit fails CI. This matters because it guarantees every theorem in the active proof tree is fully discharged.

\textbf{Inquisitor Quality Assessment:} The enforcement mechanism is \path{scripts/inquisitor.py}, which scans all Coq files across 25+ rule categories. The current status is \textbf{PASS (0 findings)} with:
\begin{itemize}
    \item 0 vacuous statements
    \item 0 admitted proofs
    \item 0 axioms in the active proof tree
    \item All physics invariance lemmas proven (gauge symmetry, Noether correspondence)
\end{itemize}

The strictness is not ceremonial: it ensures that the theorem statements presented in this chapter are actually complete and therefore reusable as axioms in subsequent reasoning. The remaining findings are primarily false positives from heuristic detection of unused hypotheses (91\% of all findings), documented in \path{INQUISITOR\_FALSE\_POSITIVES\_ANALYSIS.md}.

\subsection{What I Prove}

The key theorems proven in Coq are:
\begin{enumerate}
    \item \textbf{Observational No-Signaling}: Operations on one module cannot affect observables of other modules
    \item \textbf{$\mu$-Conservation}: The $\mu$-ledger never decreases
    \item \textbf{No Free Insight}: Strengthening certification requires explicit structure addition
    \item \textbf{Gauge Invariance}: Partition structure is invariant under $\mu$-shifts
\end{enumerate}
Each of these theorems has a concrete home in the Coq tree: observational no-signaling is developed in files such as \path{ObserverDerivation.v}, $\mu$-conservation is proven in \path{MuLedgerConservation.v}, and No Free Insight appears in \path{NoFreeInsight.v} and \path{MuNoFreeInsightQuantitative.v}. The names matter because they pin the prose to specific proof artifacts a reader can inspect.

\subsection{How to Read This Chapter}

This chapter explains the proof structure and key statements. If you are unfamiliar with Coq:
\begin{itemize}
    \item \texttt{Theorem}, \texttt{Lemma}: Statements to prove
    \item \texttt{Proof. ... Qed.}: The proof itself
    \item \texttt{forall}: For all values of this type
    \item \texttt{->}: Implies
    \item \texttt{/\textbackslash}: And (conjunction)
    \item \texttt{\textbackslash/}: Or (disjunction)
\end{itemize}

Focus on understanding the \textit{statements} (what I prove), not the proof details. Every statement is written so it can be re-derived from the definitions given in Chapters 3 and 4.

\section{The Formal Verification Campaign}

The credibility of the Thiele Machine rests on machine-checked proofs. This chapter documents the verification campaign that culminated in a full removal of \texttt{Admitted}, \texttt{admit.}, and \texttt{Axiom} declarations from the active Coq tree. The practical consequence is rebuildability: a reader can re-implement the definitions and re-prove the same claims without relying on hidden assumptions.

All proofs are verified by Coq 8.18.x. The Inquisitor enforces this invariant: any commit introducing an admit or undocumented axiom fails CI. The comprehensive static analysis also detects vacuous statements, trivial tautologies, and hidden assumptions. See \path{scripts/INQUISITOR\_GUIDE.md} for complete documentation of the 20+ rule categories and enforcement policies.

\section{Proof Architecture}

\subsection{Conceptual Hierarchy}

The proof corpus is organized by concept rather than by implementation detail:
\begin{itemize}
    \item \textbf{State and partitions}: definitions of the machine state, partition graph, and normalization.
    \item \textbf{Step semantics}: the instruction set and its inductive transition rules.
    \item \textbf{Certification and receipts}: the logic of certificates and trace decoding.
    \item \textbf{Conservation and locality}: theorems about $\mu$-monotonicity and no-signaling.
    \item \textbf{Impossibility theorems}: No Free Insight and its corollaries.
\end{itemize}

The goal is not to “encode” the implementation, but to define a minimal semantics from which every implementation can be reconstructed. Each later proof depends only on earlier definitions and lemmas, so the dependency structure is acyclic and reproducible.

\subsection{Dependency Sketch}

The proofs build outward from the state and step definitions: first the operational semantics, then conservation/locality lemmas, and finally the impossibility results that rely on those invariants. The ordering is important: no theorem about $\mu$ or locality is used before the step relation is fixed.

\section{State Definitions: Foundation Layer}

\subsection{The State Record}

\begin{lstlisting}
Record VMState := {
  vm_graph : PartitionGraph;
  vm_csrs : CSRState;
  vm_regs : list nat;
  vm_mem : list nat;
  vm_pc : nat;
  vm_mu : nat;
  vm_err : bool
}.
\end{lstlisting}

\paragraph{Understanding the VMState Record in Verification Context:}

\textbf{What is this?} This is the \textbf{same} VMState record definition from Chapter 3, repeated here in Chapter 5 to establish the verification context. Formal proofs quantify over VMState values, so every theorem statement begins by referencing these exact fields.

\textbf{Seven immutable fields:}
\begin{itemize}
    \item \textbf{vm\_graph : PartitionGraph} — The complete partition structure (modules, regions, axioms). Every locality theorem quantifies over this graph.
    \item \textbf{vm\_csrs : CSRState} — Control and status registers. Proofs about error propagation read the error CSR from this field.
    \item \textbf{vm\_regs : list nat} — General-purpose registers. Proofs about register transfer (XFER) reference this list.
    \item \textbf{vm\_mem : list nat} — Main memory. Proofs about memory access quantify over this field.
    \item \textbf{vm\_pc : nat} — Program counter. Single-step proofs track PC increments via this field.
    \item \textbf{vm\_mu : nat} — Operational $\mu$ ledger. $\mu$-conservation theorem states that this field never decreases.
    \item \textbf{vm\_err : bool} — Error latch. Once set, the VM halts. Proofs about error propagation reference this flag.
\end{itemize}

\textbf{Why immutable?} Coq records are immutable by default. Every instruction produces a new VMState rather than mutating the old one. This functional style makes proofs tractable: reasoning about state transitions reduces to comparing two record values.

\textbf{Proof quantification:} Every theorem in this chapter begins with ``forall s : VMState'' or similar, meaning the claim holds for \textit{all} possible states, not just tested examples. The record pins this universal quantification to concrete types.

\textbf{Cross-layer projection:} The Inquisitor tests extract a projection function from this definition to compare Coq semantics against Python and Verilog implementations. The field names and types define the isomorphism interface.

The record is not just a convenient bundle. It encodes the exact pieces of state that the theorems quantify over, and it matches the projection used in cross-layer tests. The constants \texttt{REG\_COUNT} and \texttt{MEM\_SIZE} in \path{coq/kernel/VMState.v} fix the widths, and helper functions such as \texttt{read\_reg} and \texttt{write\_reg} define the operational meaning of register access.

\subsection{Canonical Region Normalization}

Regions are stored in canonical form to make observational equality well-defined:
\begin{lstlisting}
Definition normalize_region (region : list nat) : list nat :=
  nodup Nat.eq_dec region.
\end{lstlisting}

\paragraph{Understanding normalize\_region:}

\textbf{What does this do?} This function removes duplicate bit indices from a region list and returns the canonical (deduplicated) form. If a region is $[3, 7, 3, 5]$, normalization yields $[3, 7, 5]$ (exact order may vary by \texttt{nodup} implementation, but duplicates are guaranteed removed).

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{Definition normalize\_region} — Declares a function named \texttt{normalize\_region}.
    \item \textbf{(region : list nat)} — Takes one argument: a list of natural numbers (bit indices).
    \item \textbf{: list nat} — Returns a list of natural numbers (the deduplicated region).
    \item \textbf{nodup Nat.eq\_dec region} — Applies Coq's \texttt{nodup} function with natural number equality decision procedure. \texttt{nodup} removes duplicates from a list; \texttt{Nat.eq\_dec} is the decidable equality for natural numbers.
\end{itemize}

\textbf{Why is normalization necessary?} Two different lists can represent the same partition region: $[3, 7, 3]$ and $[7, 3]$ both mean ``bits 3 and 7 belong to this module.'' Without normalization, observational equality comparisons would fail spuriously. Normalization ensures a unique canonical representation.

\textbf{Role in proofs:} The no-signaling theorem compares \texttt{ObservableRegion} values before and after an instruction. If regions were not normalized, the proof would have to consider all possible orderings and duplications. Normalization collapses this complexity.

\textbf{Idempotence:} Applying \texttt{normalize\_region} twice yields the same result as applying it once (proven in the next lemma). This is crucial for chaining graph operations without region drift.

\begin{theorem}[Idempotence]
\begin{lstlisting}
Lemma normalize_region_idempotent : forall region,
  normalize_region (normalize_region region) = normalize_region region.
\end{lstlisting}
\end{theorem}

\paragraph{Understanding the Idempotence Lemma:}

\textbf{What does this prove?} This lemma states that normalizing a region \textbf{twice} produces the same result as normalizing it \textbf{once}. In other words, \texttt{normalize\_region} is a \textit{fixed-point operation}.

\textbf{Lemma statement breakdown:}
\begin{itemize}
    \item \textbf{Lemma normalize\_region\_idempotent} — Names the lemma ``idempotence of normalize\_region.''
    \item \textbf{forall region} — The claim holds for \textit{all} possible region lists, not just specific examples.
    \item \textbf{normalize\_region (normalize\_region region)} — Apply normalization twice.
    \item \textbf{= normalize\_region region} — The result equals applying normalization once.
\end{itemize}

\textbf{Why is this important?} Graph operations may compose: you might split a module, then merge two modules, then split again. Each operation normalizes regions internally. Without idempotence, repeated normalization could change the canonical form unpredictably. Idempotence guarantees stability: once a region is normalized, further normalization is a no-op.

\textbf{Concrete example:} If \texttt{region = [3, 7, 3]}, then:
\begin{itemize}
    \item First normalization: \texttt{normalize\_region([3, 7, 3]) = [3, 7]} (removes duplicate 3).
    \item Second normalization: \texttt{normalize\_region([3, 7]) = [3, 7]} (already canonical, no change).
\end{itemize}
The lemma proves this behavior holds for \textit{all} region lists.

\textbf{Proof strategy:} The proof invokes \texttt{nodup\_fixed\_point}, a standard library lemma stating that \texttt{nodup} is idempotent. Since \texttt{normalize\_region} is defined as \texttt{nodup Nat.eq\_dec}, the idempotence follows directly.

\textbf{Role in larger proofs:} No-signaling and observational equality proofs chain multiple graph operations. Idempotence allows the proof to normalize regions once at the beginning and once at the end, knowing intermediate normalizations won't change the canonical form.

\begin{proof}
By \texttt{nodup\_fixed\_point}: applying \texttt{nodup} twice yields the same result, so normalization is idempotent and comparisons are stable.
\end{proof}
This lemma is more than a tidying step. Observational equality depends on normalized regions; idempotence guarantees that repeated normalization does not change what an observer sees, which is vital when a proof chains multiple graph operations together.

\subsection{Graph Well-Formedness}

\begin{lstlisting}
Definition well_formed_graph (g : PartitionGraph) : Prop :=
  all_ids_below g.(pg_modules) g.(pg_next_id).
\end{lstlisting}

\paragraph{Understanding well\_formed\_graph:}

\textbf{What is this predicate?} This defines the \textbf{well-formedness invariant} for partition graphs: every module ID must be strictly less than the graph's \texttt{pg\_next\_id} counter. This prevents stale or out-of-bounds module references.

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{Definition well\_formed\_graph} — Declares a predicate (a boolean-valued function) named \texttt{well\_formed\_graph}.
    \item \textbf{(g : PartitionGraph)} — Takes a PartitionGraph as input.
    \item \textbf{: Prop} — Returns a \textit{proposition} (a logical statement that can be true or false). In Coq, \texttt{Prop} is the type of provable claims.
    \item \textbf{all\_ids\_below g.(pg\_modules) g.(pg\_next\_id)} — Checks that every module in \texttt{pg\_modules} has an ID below \texttt{pg\_next\_id}. The helper predicate \texttt{all\_ids\_below} is defined elsewhere (likely in \path{coq/kernel/PartitionGraph.v}).
\end{itemize}

\textbf{What does ``all IDs below'' mean?} The PartitionGraph maintains a monotonic counter \texttt{pg\_next\_id} that increments each time a module is created. Every module is assigned an ID from this counter, so IDs form a dense sequence $0, 1, 2, \dots$. Well-formedness requires that no module has an ID $\geq$ \texttt{pg\_next\_id}, which would indicate a corrupted or uninitialized module.

\textbf{Why is this important?} Graph operations (PNEW, PSPLIT, PMERGE) all rely on unique module IDs. If a module could have an ID out of bounds, lookups would fail unpredictably. The well-formedness invariant guarantees that every module ID is valid.

\textbf{Preservation under operations:} The next two lemmas prove that \texttt{graph\_add\_module} and \texttt{graph\_remove} preserve well-formedness. This means that once you start with a well-formed graph (e.g., the empty graph), \textit{all} reachable graphs remain well-formed.

\textbf{Role in proofs:} Locality and conservation theorems assume well-formed graphs. The assumption \texttt{well\_formed\_graph g} appears as a precondition in nearly every major theorem. This is analogous to a type-system invariant: proofs assume the data structure satisfies its own integrity constraints.

\textbf{Physical interpretation:} Well-formedness is the ``identity discipline'' of the kernel. Just as physical systems require distinct particle labels, the kernel requires distinct module IDs. The invariant enforces this labeling scheme at the mathematical level.

\begin{theorem}[Preservation Under Add]
\begin{lstlisting}
Lemma graph_add_module_preserves_wf : forall g region axioms g' mid,
  well_formed_graph g ->
  graph_add_module g region axioms = (g', mid) ->
  well_formed_graph g'.
\end{lstlisting}
\end{theorem}

\paragraph{Understanding Preservation Under graph\_add\_module:}

\textbf{What does this prove?} This lemma states that \textbf{adding a new module} to a well-formed graph produces another well-formed graph. In other words, the \texttt{graph\_add\_module} operation preserves the well-formedness invariant.

\textbf{Lemma statement breakdown:}
\begin{itemize}
    \item \textbf{Lemma graph\_add\_module\_preserves\_wf} — Names the lemma ``well-formedness preservation under module addition.''
    \item \textbf{forall g region axioms g' mid} — The claim holds for \textit{all} graphs \texttt{g}, regions, axiom sets, resulting graphs \texttt{g'}, and module IDs \texttt{mid}.
    \item \textbf{well\_formed\_graph g} — Precondition: the original graph \texttt{g} must be well-formed.
    \item \textbf{graph\_add\_module g region axioms = (g', mid)} — Premise: calling \texttt{graph\_add\_module} on \texttt{g} produces a new graph \texttt{g'} and a fresh module ID \texttt{mid}.
    \item \textbf{well\_formed\_graph g'} — Conclusion: the resulting graph \texttt{g'} is also well-formed.
\end{itemize}

\textbf{Why is this important?} The PNEW instruction (partition new) creates a fresh module by calling \texttt{graph\_add\_module}. If this operation could violate well-formedness, the entire graph would become corrupted. This lemma guarantees that PNEW is safe: starting from a well-formed graph, PNEW produces a well-formed graph.

\textbf{What does the proof show?} The proof demonstrates that \texttt{graph\_add\_module} increments \texttt{pg\_next\_id} by exactly 1 and assigns the new module the ID \texttt{pg\_next\_id} from \textit{before} the increment. Since the original graph had all IDs below \texttt{pg\_next\_id}, and the new module gets ID = \texttt{pg\_next\_id}, and \texttt{pg\_next\_id} is then incremented, all IDs in \texttt{g'} remain below the new \texttt{pg\_next\_id}.

\textbf{Concrete example:} If \texttt{g.pg\_next\_id = 5}, then:
\begin{itemize}
    \item All existing modules have IDs $\in \{0, 1, 2, 3, 4\}$.
    \item \texttt{graph\_add\_module} assigns the new module ID = 5.
    \item \texttt{g'.pg\_next\_id} becomes 6.
    \item All IDs in \texttt{g'} are now $\in \{0, 1, 2, 3, 4, 5\} < 6$.
\end{itemize}
Thus \texttt{g'} remains well-formed.

\textbf{Role in larger proofs:} This lemma is invoked by proofs about PNEW. For example, the $\mu$-conservation proof for PNEW begins by assuming \texttt{well\_formed\_graph s.vm\_graph}, then invokes this lemma to conclude \texttt{well\_formed\_graph s'.vm\_graph} after the PNEW step.

Well-formedness only enforces the ID discipline (no module has an ID greater than or equal to \texttt{pg\_next\_id}). The key point is that this property is strong enough to prevent stale references while weak enough to be preserved by every graph operation. Disjointness and coverage are handled by operation-specific lemmas so that the global invariant does not overfit any single instruction.

\begin{theorem}[Preservation Under Remove]
\begin{lstlisting}
Lemma graph_remove_preserves_wf : forall g mid g' m,
  well_formed_graph g ->
  graph_remove g mid = Some (g', m) ->
  well_formed_graph g'.
\end{lstlisting}
\end{theorem}

\paragraph{Understanding Preservation Under graph\_remove:}

\textbf{What does this prove?} This lemma states that \textbf{removing a module} from a well-formed graph produces another well-formed graph. The \texttt{graph\_remove} operation preserves well-formedness.

\textbf{Lemma statement breakdown:}
\begin{itemize}
    \item \textbf{Lemma graph\_remove\_preserves\_wf} — Names the lemma ``well-formedness preservation under module removal.''
    \item \textbf{forall g mid g' m} — The claim holds for all graphs \texttt{g}, module IDs \texttt{mid}, resulting graphs \texttt{g'}, and removed modules \texttt{m}.
    \item \textbf{well\_formed\_graph g} — Precondition: the original graph must be well-formed.
    \item \textbf{graph\_remove g mid = Some (g', m)} — Premise: removing module \texttt{mid} succeeds, producing graph \texttt{g'} and the removed module \texttt{m}. The \texttt{Some} constructor indicates success; \texttt{None} would indicate the module didn't exist.
    \item \textbf{well\_formed\_graph g'} — Conclusion: the resulting graph is well-formed.
\end{itemize}

\textbf{Why is this important?} The PMERGE instruction removes two modules and creates a merged module. If removal could violate well-formedness, PMERGE would be unsafe. This lemma guarantees that removal is safe: all remaining modules still have valid IDs.

\textbf{What does the proof show?} Removing a module filters it out of \texttt{pg\_modules} but leaves \texttt{pg\_next\_id} unchanged. Since all IDs in the original graph were below \texttt{pg\_next\_id}, and removal only \textit{deletes} a module (doesn't add one), all IDs in \texttt{g'} remain below \texttt{pg\_next\_id}.

\textbf{Concrete example:} If \texttt{g} has modules with IDs $\{0, 1, 2, 3\}$ and \texttt{pg\_next\_id = 4}, removing module 2 leaves modules $\{0, 1, 3\}$. All remaining IDs are still $< 4$, so \texttt{g'} remains well-formed.

\textbf{Why doesn't pg\_next\_id decrement?} Module IDs are never reused. Even if module 2 is removed, future modules still get IDs $4, 5, 6, \dots$. This simplifies proofs: you never have to worry about ID collisions after removal.

\textbf{Role in larger proofs:} This lemma is invoked by proofs about PMERGE. The PMERGE proof removes two modules, then adds a merged module. The removal step uses this lemma to preserve well-formedness, and the addition step uses \texttt{graph\_add\_module\_preserves\_wf} to maintain it.

\section{Operational Semantics}

\subsection{The Instruction Type}

\begin{lstlisting}
Inductive vm_instruction :=
| instr_pnew (region : list nat) (mu_delta : nat)
| instr_psplit (module : ModuleID) (left right : list nat) (mu_delta : nat)
| instr_pmerge (m1 m2 : ModuleID) (mu_delta : nat)
| instr_lassert (module : ModuleID) (formula : string)
    (cert : lassert_certificate) (mu_delta : nat)
| instr_ljoin (cert1 cert2 : string) (mu_delta : nat)
| instr_mdlacc (module : ModuleID) (mu_delta : nat)
| instr_pdiscover (module : ModuleID) (evidence : list VMAxiom) (mu_delta : nat)
| instr_xfer (dst src : nat) (mu_delta : nat)
| instr_pyexec (payload : string) (mu_delta : nat)
| instr_chsh_trial (x y a b : nat) (mu_delta : nat)
| instr_xor_load (dst addr : nat) (mu_delta : nat)
| instr_xor_add (dst src : nat) (mu_delta : nat)
| instr_xor_swap (a b : nat) (mu_delta : nat)
| instr_xor_rank (dst src : nat) (mu_delta : nat)
| instr_emit (module : ModuleID) (payload : string) (mu_delta : nat)
| instr_reveal (module : ModuleID) (bits : nat) (cert : string) (mu_delta : nat)
| instr_oracle_halts (payload : string) (mu_delta : nat)
| instr_halt (mu_delta : nat).
\end{lstlisting}

\paragraph{Understanding the vm\_instruction Inductive Type (Verification Context):}

\textbf{What is this?} This is the \textbf{same} instruction type from Chapter 3, repeated in Chapter 5 to establish the verification context. Every theorem about instruction semantics quantifies over this type.

\textbf{Inductive type:} In Coq, an \texttt{Inductive} type defines a set of constructors. \texttt{vm\_instruction} has 18 constructors, each representing one instruction. No other instructions exist---the type is closed.

\textbf{Why does every instruction have mu\_delta?} Every instruction costs $\mu$. The \texttt{mu\_delta : nat} argument encodes the declared cost. The step semantics verifies this cost is non-negative and adds it to \texttt{s.vm\_mu}. Conservation proofs quantify over arbitrary \texttt{mu\_delta} values to show that $\mu$ never decreases.

\textbf{Instruction categories:}
\begin{itemize}
    \item \textbf{Partition operations:} \texttt{instr\_pnew}, \texttt{instr\_psplit}, \texttt{instr\_pmerge} — Create, split, merge modules.
    \item \textbf{Logical operations:} \texttt{instr\_lassert}, \texttt{instr\_ljoin} — Assert formulas with SAT certificates, join certificate chains.
    \item \textbf{Discovery:} \texttt{instr\_pdiscover}, \texttt{instr\_mdlacc} — Declare axioms, compute logarithmic model size.
    \item \textbf{Data transfer:} \texttt{instr\_xfer}, \texttt{instr\_xor\_*} — Register transfer, bitwise XOR operations.
    \item \textbf{External interaction:} \texttt{instr\_pyexec}, \texttt{instr\_emit}, \texttt{instr\_oracle\_halts} — Execute Python, emit receipts, oracle queries.
    \item \textbf{Observability:} \texttt{instr\_reveal} — Make internal state observable (costs $\mu$).
    \item \textbf{Control:} \texttt{instr\_halt} — Stop execution.
\end{itemize}

\textbf{Role in verification:} Theorems state properties for \textit{all} instructions. For example, ``$\mu$-conservation holds for all instructions'' means the proof must handle all 18 constructors. Coq enforces exhaustiveness: if you forget a constructor, the proof doesn't compile.

\textbf{Physical interpretation:} Each instruction is a \textbf{thermodynamic action}. The \texttt{mu\_delta} field is the declared ``energy cost.'' The step semantics enforces that this cost is always paid (added to \texttt{vm\_mu}), guaranteeing monotonicity.

\textbf{Comparison to Chapter 3:} This is the exact same type, but Chapter 5 emphasizes the \textit{proof} structure: how theorems quantify over instructions, how case analysis works in Coq, and how the closed type guarantees exhaustiveness.

\subsection{The Step Relation}

\begin{lstlisting}
Inductive vm_step : VMState -> vm_instruction -> VMState -> Prop := ...
\end{lstlisting}

\paragraph{Understanding the vm\_step Inductive Relation:}

\textbf{What is this?} This is the \textbf{operational semantics} of the Thiele Machine: a relation \texttt{vm\_step s instr s'} that holds if and only if executing instruction \texttt{instr} in state \texttt{s} produces state \texttt{s'}.

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{Inductive vm\_step} — Declares an inductive relation (a set of inference rules).
    \item \textbf{VMState -> vm\_instruction -> VMState -> Prop} — The relation takes three arguments: initial state, instruction, final state. It returns a \texttt{Prop} (a provable claim).
    \item \textbf{:= ...} — The body (not shown) contains 18+ inference rules, one per instruction constructor, defining exactly how each instruction transforms state.
\end{itemize}

\textbf{What does the relation express?} The relation \texttt{vm\_step s instr s'} can be read as ``executing \texttt{instr} in state \texttt{s} results in state \texttt{s'}.'' Not all triples \texttt{(s, instr, s')} satisfy the relation---only those where the instruction's preconditions hold and the state transition follows the defined semantics.

\textbf{Determinism:} For valid instructions with satisfied preconditions, the relation is deterministic: each \texttt{(s, instr)} pair has at most one successor \texttt{s'}. If preconditions fail (e.g., PSPLIT on a non-existent module), the relation may be undefined or may produce a state with \texttt{vm\_err = true}.

\textbf{Cost-charging:} Every rule updates \texttt{vm\_mu} by adding the instruction's \texttt{mu\_delta}. This is how the semantics enforces $\mu$-conservation at the definitional level.

\textbf{Error handling:} Invalid operations (e.g., PSPLIT with overlapping regions) set the error CSR and latch \texttt{vm\_err := true}. Once \texttt{vm\_err} is true, no further state changes occur (the VM halts). This explicit error latch makes error propagation provable.

\textbf{Role in proofs:} Every theorem in this chapter begins with an assumption like ``\texttt{vm\_step s instr s'}.'' The proof then reasons about properties of \texttt{s'} based on the semantics encoded in the step rules. For example, the $\mu$-conservation proof cases on the instruction type and applies the corresponding step rule to show \texttt{s'.vm\_mu $\geq$ s.vm\_mu}.

\textbf{Physical interpretation:} The step relation is the \textbf{discrete-time dynamics} of the system. Each instruction is an atomic "tick," and the relation defines the state update law. This is analogous to a Hamiltonian in physics: given the current state and action, the next state is determined.

\textbf{Comparison to Chapter 3:} Chapter 3 presented the step relation as a formal definition. Chapter 5 emphasizes how proofs \textit{use} the relation: case analysis on instructions, application of step rules, and inversion lemmas to extract preconditions from step derivations.

Each instruction has one or more step rules. Key properties:
\begin{itemize}
    \item \textbf{Deterministic}: Each (state, instruction) pair has at most one successor when its preconditions hold.
    \item \textbf{Partial on invalid inputs}: Instructions with invalid certificates or failed structural checks can be undefined.
    \item \textbf{Cost-charging}: Every rule updates \texttt{vm\_mu} by the declared instruction cost.
\end{itemize}
The error latch is explicit in the step rules. For example, \texttt{PSPLIT} and \texttt{PMERGE} each have “failure” rules in \path{coq/kernel/VMStep.v} that leave the graph unchanged but set the error CSR and latch \texttt{vm\_err}. This design makes error propagation explicit and therefore available to proofs, rather than being implicit behavior of an implementation language.

This gives a complete operational semantics: given a well-formed state and a valid instruction, the next state is uniquely determined.

\section{Conservation and Locality}

This file establishes the physical laws of the Thiele Machine kernel—properties that hold for all executions without exception.

\subsection{Observables}

\begin{lstlisting}
Definition Observable (s : VMState) (mid : nat) : option (list nat * nat) :=
  match graph_lookup s.(vm_graph) mid with
  | Some modstate => Some (normalize_region modstate.(module_region), s.(vm_mu))
  | None => None
  end.

Definition ObservableRegion (s : VMState) (mid : nat) : option (list nat) :=
  match graph_lookup s.(vm_graph) mid with
  | Some modstate => Some (normalize_region modstate.(module_region))
  | None => None
  end.
\end{lstlisting}
\paragraph{Understanding Observable and ObservableRegion:}

\textbf{What are these functions?} These define the \textbf{observable interface} of modules: what an external observer can see about a module's state. They extract only the visible information (partition region and $\mu$ ledger), hiding internal implementation details like axioms.

\textbf{Syntax breakdown for Observable:}
\begin{itemize}
    \item \textbf{Definition Observable} — Declares a function named \texttt{Observable}.
    \item \textbf{(s : VMState) (mid : nat)} — Takes a state \texttt{s} and a module ID \texttt{mid}.
    \item \textbf{: option (list nat * nat)} — Returns an optional pair: (region, $\mu$). \texttt{None} if the module doesn't exist.
    \item \textbf{match graph\_lookup s.(vm\_graph) mid with} — Look up module \texttt{mid} in the graph.
    \item \textbf{Some modstate => Some (normalize\_region ..., s.(vm\_mu))} — If found, return normalized region and current $\mu$ value.
    \item \textbf{None => None} — If not found, return \texttt{None}.
\end{itemize}

\textbf{ObservableRegion difference:} This variant returns \textit{only} the region (without $\mu$). This allows stating no-signaling purely in terms of partition structure, independent of cost accounting.

\textbf{Why normalize\_region?} Without normalization, two observationally equivalent regions $[3, 7, 3]$ and $[7, 3]$ would compare as different. Normalization ensures canonical representation.

\textbf{What is NOT observable?} The module's \texttt{module\_axioms} field is \textit{not} included. Axioms are internal implementation details---two modules with the same region but different axioms are observationally equivalent. This design choice makes the observable interface minimal.

\textbf{Role in theorems:} The no-signaling theorem states that \texttt{ObservableRegion s mid = ObservableRegion s' mid} when an instruction doesn't target \texttt{mid}. This pins observational equality to a precise mathematical definition.

\textbf{Physical interpretation:} Observables are the ``measurement outcomes'' of the system. Just as quantum mechanics distinguishes observable operators from internal state vectors, the Thiele Machine distinguishes observable regions from internal axiom structures. The $\mu$ ledger is observable because it represents paid thermodynamic cost.

\textbf{Why option type?} If a module ID doesn't exist, \texttt{Observable} returns \texttt{None} rather than failing. This makes the function total (defined for all inputs) and simplifies proofs: you don't need separate existence checks.
Note: Axioms are \textbf{not} observable—they are internal implementation details. Observables contain only partition regions and the $\mu$-ledger, which is the cost-visible interface of the model.
The distinction between \texttt{Observable} and \texttt{ObservableRegion} is deliberate. \texttt{Observable} includes the $\mu$-ledger to capture the paid structural cost, while \texttt{ObservableRegion} strips the $\mu$ field so that no-signaling can be stated purely in terms of partition structure. This avoids a loophole where a proof of locality could fail merely because the $\mu$-ledger changed, even though no region membership changed.

\subsection{Instruction Target Sets}

\begin{lstlisting}
Definition instr_targets (instr : vm_instruction) : list nat :=
  match instr with
  | instr_pnew _ _ => []
  | instr_psplit mid _ _ _ => [mid]
  | instr_pmerge m1 m2 _ => [m1; m2]
  | instr_lassert mid _ _ _ => [mid]
  ...
  end.
\end{lstlisting}

\paragraph{Understanding instr\_targets:}

\textbf{What does this function do?} This extracts the \textbf{target module IDs} from an instruction: the set of modules that the instruction directly operates on. For example, PSPLIT targets one module (the one being split), PMERGE targets two modules (the ones being merged).

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{Definition instr\_targets} — Declares a function to extract target modules.
    \item \textbf{(instr : vm\_instruction)} — Takes an instruction as input.
    \item \textbf{: list nat} — Returns a list of module IDs (natural numbers).
    \item \textbf{match instr with} — Case analysis on the instruction type.
    \item \textbf{instr\_pnew \_ \_ => []} — PNEW creates a new module, doesn't target existing modules, so returns empty list.
    \item \textbf{instr\_psplit mid \_ \_ \_ => [mid]} — PSPLIT targets module \texttt{mid} (the one being split).
    \item \textbf{instr\_pmerge m1 m2 \_ => [m1; m2]} — PMERGE targets two modules \texttt{m1} and \texttt{m2}.
    \item \textbf{instr\_lassert mid \_ \_ \_ => [mid]} — LASSERT adds an axiom to module \texttt{mid}.
\end{itemize}

\textbf{Why is this important?} The no-signaling theorem uses \texttt{instr\_targets} to state locality: if module \texttt{mid} is \textit{not} in \texttt{instr\_targets(instr)}, then the instruction cannot affect \texttt{mid}'s observable region. This function precisely defines ``does not target.''

\textbf{What about instructions that don't target modules?} Instructions like XFER (register transfer) and HALT don't target any modules, so they return empty lists. The no-signaling theorem then states that such instructions don't affect \textit{any} module's observable region.

\textbf{Concrete example:}
\begin{itemize}
    \item \texttt{instr\_targets(PSPLIT 5 [...]) = [5]} — Only module 5 is targeted.
    \item \texttt{instr\_targets(PMERGE 3 7 [...]) = [3, 7]} — Modules 3 and 7 are targeted.
    \item \texttt{instr\_targets(PNEW [...]) = []} — No existing modules targeted.
\end{itemize}

\textbf{Role in proofs:} The no-signaling proof begins with the assumption \texttt{$\sim$ In mid (instr\_targets instr)}, meaning \texttt{mid} is not in the target list. The proof then shows this guarantees \texttt{ObservableRegion s mid = ObservableRegion s' mid}.

\textbf{Physical interpretation:} \texttt{instr\_targets} defines the \textbf{causal light cone} of an instruction: the set of modules that can be directly affected. Modules outside this set are causally isolated---they cannot receive signals from the instruction.

\subsection{The No-Signaling Theorem}

% Figure 2: No-Signaling Visualization
\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1.8, 
    module/.style={rectangle, draw, fill=blue!20, minimum width=4.0cm, minimum height=2.2cm, align=center},
    region/.style={rectangle, draw, dashed, fill=gray!10, minimum width=4.0cm, minimum height=2.9cm},
    arrow/.style={->, >=stealth, thick}
], node distance=3cm]
    % Left side: Before operation
    \node at (-4, 2.5) {\textbf{State $s$}};
    
    \node[region] (r1) at (-5.5, 0.5) {};
    \node[module, align=center, text width=3.5cm, font=\normalsize] (m1) at (-5.5, 0.5) {Module\\$mid_1$};
    \node at (-5.5, -0.8) {\footnotesize Region $R_1$};
    
    \node[region] (r2) at (-2.5, 0.5) {};
    \node[module, fill=green!30, align=center, text width=3.5cm, font=\normalsize] (m2) at (-2.5, 0.5) {Module\\$mid_2$};
    \node at (-2.5, -0.8) {\footnotesize Region $R_2$};
    \node at (-2.5, -1.3) {\color{red}\footnotesize (target)};
    
    % Arrow showing operation
    \draw[->, >=stealth, ultra thick, red, shorten >=2pt, shorten <=2pt] (-0.8, 0.5) -- (0.8, 0.5);
    \node at (0, 1) {\texttt{instr} targets $mid_2$};
    
    % Right side: After operation
    \node at (4, 2.5) {\textbf{State $s'$}};
    
    \node[region] (r1p) at (2.5, 0.5) {};
    \node[module, align=center, text width=3.5cm, font=\normalsize] (m1p) at (2.5, 0.5) {Module\\$mid_1$};
    \node at (2.5, -0.8) {\footnotesize Region $R_1$};
    \node at (2.5, -1.3) {\color{blue}\footnotesize \textbf{unchanged}};
    
    \node[region] (r2p) at (5.5, 0.5) {};
    \node[module, fill=orange!30, align=center, text width=3.5cm, font=\normalsize] (m2p) at (5.5, 0.5) {Module\\$mid_2'$};
    \node at (5.5, -0.8) {\footnotesize Region $R_2'$};
    \node at (5.5, -1.3) {\color{red}\footnotesize (modified)};
    
    % Theorem statement box
    \node[draw, fill=yellow!20, rounded corners, text width=10cm, align=center] at (0, -3) {
        \textbf{No-Signaling Theorem:} If $mid \notin$ \texttt{instr\_targets(instr)}\\
        then \texttt{ObservableRegion}$(s, mid) =$ \texttt{ObservableRegion}$(s', mid)$
    };
\end{tikzpicture}
\caption{No-signaling: operations on one module cannot affect observables of other modules.}
\label{fig:no-signaling}
\end{figure}

\paragraph{Understanding Figure \ref{fig:no-signaling}:}

\textbf{Two modules (boxes):}
\begin{itemize}
    \item \textbf{Module A (blue):} Operations targeting this module (arrow pointing in)
    \item \textbf{Module B (green):} Non-targeted module (dashed red X - no effect allowed)
\end{itemize}

\textbf{Operation arrow:} Points to Module A - instruction targets only A

\textbf{Red dashed X:} Between Module A and Module B - forbidden causal path. No signaling allowed.

\textbf{Bottom yellow box:} Theorem statement - If $mid \notin$ instr\_targets(instr), then ObservableRegion$(s, mid) =$ ObservableRegion$(s', mid)$

\textbf{Key insight:} Computational Bell locality - operations on one module cannot affect observables of causally isolated modules. Partition structure enforces spatial locality.

\begin{theorem}[Observational No-Signaling]
\begin{lstlisting}
Theorem observational_no_signaling : forall s s' instr mid,
  well_formed_graph s.(vm_graph) ->
  mid < pg_next_id s.(vm_graph) ->
  vm_step s instr s' ->
  ~ In mid (instr_targets instr) ->
  ObservableRegion s mid = ObservableRegion s' mid.
\end{lstlisting}
\end{theorem}

\paragraph{Understanding the Observational No-Signaling Theorem:}

\textbf{What does this theorem prove?} This proves \textbf{locality}: if an instruction does not target a module \texttt{mid}, then that instruction cannot change \texttt{mid}'s observable region. In other words, you cannot send signals to a remote module by operating on local state.

\textbf{Theorem statement breakdown:}
\begin{itemize}
    \item \textbf{Theorem observational\_no\_signaling} — Names the theorem ``observational no-signaling (locality).''
    \item \textbf{forall s s' instr mid} — The claim holds for \textit{all} initial states \texttt{s}, final states \texttt{s'}, instructions \texttt{instr}, and module IDs \texttt{mid}.
    \item \textbf{well\_formed\_graph s.(vm\_graph)} — Precondition: the initial graph must be well-formed (all module IDs valid).
    \item \textbf{mid < pg\_next\_id s.(vm\_graph)} — Precondition: module \texttt{mid} must exist (its ID is below the next ID counter).
    \item \textbf{vm\_step s instr s'} — Premise: executing \texttt{instr} in state \texttt{s} produces state \texttt{s'}.
    \item \textbf{$\sim$ In mid (instr\_targets instr)} — Premise: \texttt{mid} is \textit{not} in the instruction's target set (the instruction does not directly operate on \texttt{mid}).
    \item \textbf{ObservableRegion s mid = ObservableRegion s' mid} — Conclusion: the observable region of \texttt{mid} is unchanged.
\end{itemize}

\textbf{Why is this theorem fundamental?} This is the computational analog of \textbf{Bell locality} in physics: operations on one subsystem cannot instantaneously affect another causally isolated subsystem. Without this property, the partition structure would be meaningless---any operation could scramble the entire graph.

\textbf{What does the proof show?} The proof proceeds by case analysis on the instruction type:
\begin{itemize}
    \item \textbf{Partition operations (PNEW, PSPLIT, PMERGE):} These only modify modules in \texttt{instr\_targets}. If \texttt{mid} is not targeted, its region remains unchanged.
    \item \textbf{Logical operations (LASSERT, LJOIN):} These only modify axioms of targeted modules. Since axioms are not observable, \texttt{ObservableRegion} is unchanged even for targeted modules. For non-targeted modules, nothing changes at all.
    \item \textbf{Data transfer (XFER, XOR\_*):} These modify registers/memory, not the partition graph, so \texttt{ObservableRegion} is unchanged for all modules.
\end{itemize}

\textbf{Concrete example:} If module 5 has region $[3, 7]$ and you execute \texttt{PSPLIT 3 ...} (splitting module 3), module 5's region remains $[3, 7]$ because 5 is not in \texttt{instr\_targets(PSPLIT 3)}.

\textbf{Physical interpretation:} This theorem enforces \textbf{causal structure}. Just as special relativity forbids faster-than-light signaling, the Thiele Machine forbids action-at-a-distance in the partition graph. The partition structure defines a ``space,'' and this theorem guarantees spatial locality.

\textbf{Role in larger proofs:} This theorem is invoked by cryptographic security proofs and CHSH violation analyses. It guarantees that partition modules are truly independent: you cannot leak information from one partition to another without explicit operations (like PMERGE or REVEAL).

\begin{proof}
By case analysis on the instruction. For each instruction type:
\begin{enumerate}
    \item If \texttt{mid} is not in \texttt{instr\_targets}, the instruction does not modify module \texttt{mid}
    \item Graph operations (pnew, psplit, pmerge) only affect targeted modules
    \item Logical operations (lassert, ljoin) only affect targeted module axioms (which are not observable)
    \item Memory operations (xfer, xor\_*) do not modify the partition graph
    \item Therefore, \texttt{ObservableRegion} is unchanged
\end{enumerate}
\end{proof}

\textbf{Physical Interpretation}: You cannot send signals to a remote module by operating on local state. This is the computational analog of Bell locality.

\subsection{Gauge Symmetry}

% Figure 3: Gauge Symmetry Visualization
\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1.8, 
    state/.style={rectangle, draw, fill=blue!10, minimum width=5.4cm, minimum height=3.6cm, align=center},
    field/.style={rectangle, draw, fill=white, minimum width=4.7cm, minimum height=1.0cm, align=center},
    arrow/.style={->, >=stealth, thick}
], node distance=3cm]
    % Left state
    \node[state, font=\normalsize] (s1) at (-3.5, 0) {};
    \node at (-3.5, 1.4) {\textbf{State $s$}};
    \node[field] at (-3.5, 0.5) {\texttt{vm\_graph} = $G$};
    \node[field, fill=red!20] at (-3.5, -0.2) {\texttt{vm\_mu} = $\mu$};
    \node[field] at (-3.5, -0.9) {\texttt{vm\_regs, ...}};
    
    % Arrow with shift
    \draw[->, >=stealth, ultra thick, blue, shorten >=2pt, shorten <=2pt] (-1.5, 0) -- (1.5, 0);
    \node at (0, 0.6) {\texttt{mu\_gauge\_shift}$(k)$};
    \node at (0, -0.4) {$\mu \mapsto \mu + k$};
    
    % Right state
    \node[state, font=\normalsize] (s2) at (3.5, 0) {};
    \node at (3.5, 1.4) {\textbf{State $s'$}};
    \node[field] at (3.5, 0.5) {\texttt{vm\_graph} = $G$};
    \node[field, fill=green!20] at (3.5, -0.2) {\texttt{vm\_mu} = $\mu + k$};
    \node[field] at (3.5, -0.9) {\texttt{vm\_regs, ...}};
    
    % Invariance annotation
    \draw[<->, >=stealth, very thick, dashed, red, shorten >=2pt, shorten <=2pt] (-3.5, -2) -- (3.5, -2);
    \node at (0, -2.5) {\texttt{conserved\_partition\_structure}$(s) =$ \texttt{conserved\_partition\_structure}$(s')$};
    
    % Physical analog
    \node[draw, fill=yellow!20, rounded corners, text width=8cm, align=center] at (0, -4) {
        \textbf{Physical Analog (Noether):} Gauge symmetry ($\mu$-shift freedom)\\
        $\Leftrightarrow$ Conservation of partition structure
    };
\end{tikzpicture}
\caption{Gauge symmetry: shifting $\mu$ by a constant preserves partition structure (computational Noether's theorem).}
\label{fig:gauge-symmetry}
\end{figure}

\paragraph{Understanding Figure \ref{fig:gauge-symmetry}:}

\textbf{Two states (boxes):}
\begin{itemize}
    \item \textbf{State $s$ (left):} vm\_graph = $G$, vm\_mu = $\mu$ (red box), vm\_regs, ...
    \item \textbf{State $s'$ (right):} vm\_graph = $G$ (unchanged!), vm\_mu = $\mu + k$ (green box, shifted), vm\_regs, ...
\end{itemize}

\textbf{Thick blue arrow:} Gauge transformation - mu\_gauge\_shift$(k)$ applies $\mu \mapsto \mu + k$

\textbf{Bottom dashed red line:} Invariance - conserved\_partition\_structure$(s) =$ conserved\_partition\_structure$(s')$ (partition graph $G$ unchanged)

\textbf{Bottom yellow box:} Physical analog (Noether's theorem) - Gauge symmetry ($\mu$-shift freedom) $\Leftrightarrow$ Conservation of partition structure

\textbf{Key insight:} Absolute $\mu$ value is arbitrary (gauge freedom). Only $\mu$ differences matter. Partition structure is gauge-invariant.

\begin{lstlisting}
Definition mu_gauge_shift (k : nat) (s : VMState) : VMState :=
  {| vm_regs := s.(vm_regs);
     vm_mem := s.(vm_mem);
     vm_csrs := s.(vm_csrs);
     vm_pc := s.(vm_pc);
     vm_graph := s.(vm_graph);
     vm_mu := s.(vm_mu) + k;
     vm_err := s.(vm_err) |}.
\end{lstlisting}

\paragraph{Understanding mu\_gauge\_shift:}

\textbf{What is this function?} This defines a \textbf{gauge transformation}: shifting the $\mu$ ledger by a constant $k$ while leaving all other state fields unchanged. This is analogous to shifting the zero point of potential energy in physics.

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{Definition mu\_gauge\_shift} — Declares a function named \texttt{mu\_gauge\_shift}.
    \item \textbf{(k : nat) (s : VMState)} — Takes a shift amount \texttt{k} and a state \texttt{s}.
    \item \textbf{: VMState} — Returns a new VMState (records are immutable).
    \item \textbf{\{| vm\_regs := s.(vm\_regs); ... |\}} — Coq record update syntax. Copies all fields from \texttt{s} except \texttt{vm\_mu}.
    \item \textbf{vm\_mu := s.(vm\_mu) + k} — The $\mu$ ledger is shifted by \texttt{k}.
\end{itemize}

\textbf{Why is this called a gauge transformation?} In physics, a \textit{gauge transformation} is a change of coordinates or reference frame that doesn't affect observable quantities. Here, shifting $\mu$ by a constant doesn't change the partition structure---only the absolute $\mu$ value changes, but $\mu$ \textit{differences} (the physically meaningful quantities) remain the same.

\textbf{What is preserved under gauge shifts?} The partition graph \texttt{vm\_graph} is completely unchanged. The registers, memory, CSRs, PC, and error latch are also unchanged. Only the $\mu$ accounting offset changes.

\textbf{Physical analog (Noether's theorem):} In physics, symmetries correspond to conserved quantities (Noether's theorem). Here:
\begin{itemize}
    \item \textbf{Symmetry:} $\mu$-shift freedom (gauge invariance).
    \item \textbf{Conserved quantity:} Partition structure (the graph topology).
\end{itemize}
The next theorem proves this correspondence: gauge-shifted states have identical partition structures.

\textbf{Concrete example:} If \texttt{s.vm\_mu = 100} and you apply \texttt{mu\_gauge\_shift(50, s)}, the result has \texttt{vm\_mu = 150} but the same graph, registers, etc. If you then execute an instruction costing $\mu = 10$, both the original and shifted states reach $\mu = 110$ and $\mu = 160$ respectively---the difference (50) is preserved.

\textbf{Role in theorems:} The gauge invariance theorem states that \texttt{conserved\_partition\_structure s = conserved\_partition\_structure (mu\_gauge\_shift k s)}, meaning the partition structure is invariant under $\mu$-shifts. This is the computational analog of energy conservation via time-translation symmetry.

\begin{theorem}[Gauge Invariance]
\begin{lstlisting}
Theorem kernel_conservation_mu_gauge : forall s k,
  conserved_partition_structure s = 
  conserved_partition_structure (nat_action k s).
\end{lstlisting}
\end{theorem}

\paragraph{Understanding kernel\_conservation\_mu\_gauge:}

\textbf{What this proves:} Partition structure is gauge-invariant under $\mu$-shifts. This is the computational Noether's theorem: gauge symmetry (freedom to shift $\mu$ baseline) corresponds to conservation of partition topology. See full explanation in later instance of this theorem for complete first-principles breakdown.

\textbf{Physical Interpretation}: Noether's theorem—gauge symmetry (freedom to shift $\mu$ by a constant) corresponds to conservation of partition structure.

\subsection{$\mu$-Conservation}

% Figure 4: μ-Conservation Visualization
\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1.8, 
    state/.style={circle, draw, fill=blue!20, minimum size=1cm},
    arrow/.style={->, >=stealth, thick}
], node distance=3cm]
    % States in sequence
    \node[state, font=\normalsize] (s0) at (0, 0) {$s_0$};
    \node[state, font=\normalsize] (s1) at (3, 0) {$s_1$};
    \node[state, font=\normalsize] (s2) at (6, 0) {$s_2$};
    \node[state, font=\normalsize] (s3) at (9, 0) {$s_3$};
    \node at (11, 0) {$\cdots$};
    
    % Transitions with costs
    \draw[arrow] (s0) -- node[above, yshift=6pt, sloped, pos=0.5, font=\small] {\footnotesize $+\mu_1$} (s1);
    \draw[arrow] (s1) -- node[above, yshift=6pt, sloped, pos=0.5, font=\small] {\footnotesize $+\mu_2$} (s2);
    \draw[arrow] (s2) -- node[above, yshift=6pt, sloped, pos=0.5, font=\small] {\footnotesize $+\mu_3$} (s3);
    \draw[arrow, shorten >=2pt, shorten <=2pt] (s3) -- (10.5, 0);
    
    % μ values below
    \node at (0, -1) {$\mu = 0$};
    \node at (3, -1) {$\mu = \mu_1$};
    \node at (6, -1) {$\mu = \mu_1 + \mu_2$};
    \node at (9, -1) {$\mu = \sum_{i=1}^{3} \mu_i$};
    
    % Monotonicity arrow
    \draw[->, >=stealth, ultra thick, red, dashed, shorten >=2pt, shorten <=2pt] (0, -1.8) -- (11, -1.8);
    \node at (5.5, -2.3) {\color{red}\textbf{Monotonically Non-Decreasing}};
    
    % Conservation equation
    \node[draw, fill=green!20, rounded corners, text width=8cm, align=center] at (5, -3.8) {
        \textbf{Conservation Law:}\\
        $\mu(s') \geq \mu(s)$ for all valid transitions $s \to s'$\\
        $\mu(\text{final}) = \mu(\text{init}) + \sum_{i} \text{cost}(\text{instr}_i)$
    };
\end{tikzpicture}
\caption{$\mu$-conservation: the ledger only grows, never decreases.}
\label{fig:mu-conservation}
\end{figure}

\paragraph{Understanding Figure \ref{fig:mu-conservation}:}

\textbf{Horizontal sequence:} States $s_0 \to s_1 \to s_2 \to s_3 \cdots$ (blue circles)

\textbf{Transition arrows:} Labeled with costs $+\mu_1, +\mu_2, +\mu_3$ - each instruction adds $\mu$-cost

\textbf{Below each state:} $\mu$ values showing accumulation - $\mu = 0, \mu = \mu_1, \mu = \mu_1 + \mu_2, \mu = \sum_{i=1}^{3} \mu_i$

\textbf{Red dashed arrow (bottom):} Monotonically Non-Decreasing - ledger only grows

\textbf{Bottom green box:} Conservation Law equations - $\mu(s') \geq \mu(s)$ for all transitions, $\mu(\text{final}) = \mu(\text{init}) + \sum_i \text{cost}(\text{instr}_i)$

\textbf{Key insight:} Second Law of Thermodynamics for Thiele Machine - $\mu$ never decreases. No free operations. Exact accounting guaranteed.

\begin{theorem}[$\mu$-Conservation]
\begin{lstlisting}
Theorem mu_conservation_kernel : forall s s' instr,
  vm_step s instr s' ->
  s'.(vm_mu) >= s.(vm_mu).
\end{lstlisting}
\end{theorem}

\paragraph{Understanding the $\mu$-Conservation Theorem:}

\textbf{What does this prove?} This proves the \textbf{Second Law of Thermodynamics} for the Thiele Machine: the $\mu$ ledger never decreases. Every instruction either increases $\mu$ or leaves it unchanged---there are no "free" operations.

\textbf{Theorem statement breakdown:}
\begin{itemize}
    \item \textbf{Theorem mu\_conservation\_kernel} — Names the theorem ``$\mu$-conservation for the kernel.''
    \item \textbf{forall s s' instr} — The claim holds for \textit{all} initial states \texttt{s}, final states \texttt{s'}, and instructions \texttt{instr}.
    \item \textbf{vm\_step s instr s'} — Premise: executing \texttt{instr} in state \texttt{s} produces state \texttt{s'}.
    \item \textbf{s'.(vm\_mu) >= s.(vm\_mu)} — Conclusion: the final $\mu$ value is greater than or equal to the initial $\mu$ value.
\end{itemize}

\textbf{Why $\geq$ instead of $>$?} The theorem allows $\mu$ to remain unchanged ($s'.vm\_mu = s.vm\_mu$) if an instruction has zero cost. In practice, every real instruction has positive cost, but the theorem is stated with $\geq$ to cover the degenerate case.

\textbf{What does the proof show?} The proof examines the \texttt{vm\_step} relation: every step rule calls \texttt{apply\_cost s instr}, which updates \texttt{vm\_mu} to \texttt{s.vm\_mu + instruction\_cost(instr)}. Since \texttt{instruction\_cost} returns a \texttt{nat} (natural number, always $\geq 0$), the result is always $\geq$ the original \texttt{vm\_mu}.

\textbf{Why is this fundamental?} This theorem is the kernel's \textbf{thermodynamic anchor}. It guarantees:
\begin{itemize}
    \item \textbf{No free computation:} Every operation costs $\mu$. You cannot gain structure, information, or correlation without paying.
    \item \textbf{Irreversibility:} $\mu$ growth tracks irreversible bit operations (proven in the irreversibility theorem).
    \item \textbf{Accountability:} The $\mu$ ledger is a complete audit trail. If $\mu$ grew by 100, exactly 100 units of structural cost were paid.
\end{itemize}

\textbf{Physical interpretation:} This is \textit{exactly} the Second Law of Thermodynamics: entropy (here, $\mu$) never decreases in an isolated system. The Thiele Machine is a reversible model, but the $\mu$ ledger tracks the thermodynamic cost of maintaining reversibility. In physics, running a computation reversibly costs $k_B T \ln 2$ per erased bit (Landauer's bound); here, running a partition operation costs $\mu$ per structural change.

\textbf{Concrete example:} If \texttt{s.vm\_mu = 50} and you execute PNEW with \texttt{mu\_delta = 10}, then \texttt{s'.vm\_mu = 60}. The theorem guarantees $60 \geq 50$. If you execute 5 instructions with costs $[10, 15, 20, 5, 8]$, the final $\mu$ is $50 + 10 + 15 + 20 + 5 + 8 = 108$, and the theorem guarantees $108 \geq 50$ after each step.

\textbf{Role in larger proofs:} This single-step theorem is the base case for multi-step conservation (\texttt{run\_vm\_mu\_conservation}). It also supports the No Free Insight theorem: strengthening a predicate requires $\mu > 0$, proven by invoking $\mu$-conservation on the trace.

\begin{proof}
By definition of \texttt{vm\_step}: every step rule updates \texttt{vm\_mu} to \texttt{apply\_cost s instr}, which adds a non-negative cost.
\end{proof}

\section{Multi-Step Conservation}

\subsection{Run Function}

\begin{lstlisting}
Fixpoint run_vm (fuel : nat) (trace : Trace) (s : VMState) : VMState :=
  match fuel with
  | O => s
  | S fuel' =>
      match nth_error trace s.(vm_pc) with
      | None => s
      | Some instr => run_vm fuel' trace (step_vm s instr)
      end
  end.
\end{lstlisting}

\paragraph{Understanding run\_vm:}

\textbf{What does this function do?} This executes \textbf{multiple instructions} by recursively stepping the VM. It runs up to \texttt{fuel} instructions from a trace (instruction list), fetching each instruction from the current program counter \texttt{s.vm\_pc}.

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{Fixpoint run\_vm} — Declares a recursive function. \texttt{Fixpoint} is Coq's keyword for structurally recursive functions.
    \item \textbf{(fuel : nat)} — The \textit{fuel} parameter limits recursion depth. After \texttt{fuel} steps, execution stops (prevents infinite loops in Coq).
    \item \textbf{(trace : Trace)} — The instruction sequence (a list of instructions).
    \item \textbf{(s : VMState)} — The current VM state.
    \item \textbf{: VMState} — Returns the final state after executing up to \texttt{fuel} instructions.
    \item \textbf{match fuel with | O => s} — Base case: if fuel is zero, return the current state unchanged.
    \item \textbf{| S fuel' =>} — Recursive case: if fuel is $n+1$, we have $n$ steps remaining.
    \item \textbf{nth\_error trace s.(vm\_pc)} — Fetch the instruction at index \texttt{vm\_pc} from the trace. Returns \texttt{Some instr} if found, \texttt{None} if out of bounds.
    \item \textbf{| None => s} — If PC is out of bounds, halt (return current state).
    \item \textbf{| Some instr => run\_vm fuel' trace (step\_vm s instr)} — If instruction found, execute it via \texttt{step\_vm}, then recurse with decremented fuel.
\end{itemize}

\textbf{Why fuel?} Coq requires all functions to terminate. Without fuel, \texttt{run\_vm} could loop forever (e.g., if the trace contains an infinite loop). Fuel bounds the recursion depth, making the function structurally recursive on \texttt{fuel}. In proofs, you quantify over arbitrary fuel: \texttt{forall fuel, ...}.

\textbf{What is step\_vm?} This is a deterministic wrapper around \texttt{vm\_step}: given \texttt{(s, instr)}, it returns the unique \texttt{s'} such that \texttt{vm\_step s instr s'}, or returns \texttt{s} unchanged if the step is undefined.

\textbf{Halting conditions:}
\begin{itemize}
    \item Fuel exhausted: \texttt{fuel = O}.
    \item PC out of bounds: \texttt{nth\_error trace s.vm\_pc = None}.
    \item Implicit: If an instruction sets \texttt{vm\_err = true}, subsequent steps likely become no-ops (depends on \texttt{step\_vm} implementation).
\end{itemize}

\textbf{Role in theorems:} Multi-step theorems (like \texttt{run\_vm\_mu\_conservation}) quantify over \texttt{run\_vm} rather than single \texttt{vm\_step}. This function bridges single-step semantics and multi-step behavior.

\textbf{Physical interpretation:} \texttt{run\_vm} is the \textbf{discrete-time evolution operator}. Given an initial state and a trace (the "Hamiltonian"), it computes the state after \texttt{fuel} time steps. This is analogous to solving the equations of motion in physics.

\subsection{Ledger Entries}

\begin{lstlisting}
Fixpoint ledger_entries (fuel : nat) (trace : Trace) (s : VMState) : list nat :=
  match fuel with
  | O => []
  | S fuel' =>
      match nth_error trace s.(vm_pc) with
      | None => []
      | Some instr =>
          instruction_cost instr :: ledger_entries fuel' trace (step_vm s instr)
      end
  end.

Definition ledger_sum (entries : list nat) : nat := fold_left Nat.add entries 0.
\end{lstlisting}

\paragraph{Understanding ledger\_entries and ledger\_sum:}

\textbf{What does ledger\_entries do?} This extracts the \textbf{sequence of $\mu$ costs} paid during execution. It mirrors \texttt{run\_vm}'s recursion but collects instruction costs instead of computing states.

\textbf{Syntax breakdown for ledger\_entries:}
\begin{itemize}
    \item \textbf{Fixpoint ledger\_entries} — Declares a recursive function (structurally recursive on \texttt{fuel}).
    \item \textbf{(fuel : nat) (trace : Trace) (s : VMState)} — Same parameters as \texttt{run\_vm}.
    \item \textbf{: list nat} — Returns a list of natural numbers (the $\mu$ costs of each executed instruction).
    \item \textbf{match fuel with | O => []} — Base case: no fuel, empty ledger.
    \item \textbf{| S fuel' =>} — Recursive case: fuel remaining.
    \item \textbf{nth\_error trace s.(vm\_pc)} — Fetch instruction at current PC.
    \item \textbf{| None => []} — If PC out of bounds, return empty ledger (halt).
    \item \textbf{| Some instr => instruction\_cost instr :: ...} — Prepend the instruction's $\mu$ cost to the ledger.
    \item \textbf{ledger\_entries fuel' trace (step\_vm s instr)} — Recurse on the stepped state.
\end{itemize}

\textbf{Structure mirrors run\_vm:} The recursion structure is identical to \texttt{run\_vm}, ensuring that the ledger corresponds exactly to the executed trace. If \texttt{run\_vm} executes $n$ instructions, \texttt{ledger\_entries} returns a list of length $n$.

\textbf{What does ledger\_sum do?} This sums the ledger entries to compute the total $\mu$ cost:
\begin{itemize}
    \item \textbf{Definition ledger\_sum} — Declares a function.
    \item \textbf{(entries : list nat)} — Takes a list of natural numbers (the ledger).
    \item \textbf{: nat} — Returns the sum.
    \item \textbf{fold\_left Nat.add entries 0} — Left-fold addition over the list, starting from 0. This computes $0 + e_1 + e_2 + \dots + e_n$.
\end{itemize}

\textbf{Why separate ledger\_entries and ledger\_sum?} Separating these functions simplifies proofs. You can prove properties about the ledger list structure (e.g., length, individual entries) independently from the sum.

\textbf{Concrete example:} If you execute 3 instructions with costs $[10, 15, 20]$:
\begin{itemize}
    \item \texttt{ledger\_entries(3, trace, s) = [10, 15, 20]}
    \item \texttt{ledger\_sum([10, 15, 20]) = 10 + 15 + 20 = 45}
\end{itemize}

\textbf{Role in theorems:} The conservation corollary (\texttt{run\_vm\_mu\_conservation}) states that the final $\mu$ equals initial $\mu$ plus \texttt{ledger\_sum}. This makes the thermodynamic accounting explicit: every $\mu$ unit in the ledger corresponds to a paid cost.

\subsection{Conservation Theorem}

\begin{theorem}[Run Conservation]
\begin{lstlisting}
Corollary run_vm_mu_conservation :
  forall fuel trace s,
    (run_vm fuel trace s).(vm_mu) =
    s.(vm_mu) + ledger_sum (ledger_entries fuel trace s).
\end{lstlisting}
\end{theorem}

\paragraph{Understanding run\_vm\_mu\_conservation:}

\textbf{What does this prove?} This proves \textbf{multi-step $\mu$-conservation}: after running \texttt{fuel} instructions, the final $\mu$ equals the initial $\mu$ plus the sum of all instruction costs. This generalizes \texttt{mu\_conservation\_kernel} from single steps to arbitrary traces.

\textbf{Corollary statement breakdown:}
\begin{itemize}
    \item \textbf{Corollary run\_vm\_mu\_conservation} — Names the corollary (a theorem derived from another theorem).
    \item \textbf{forall fuel trace s} — The claim holds for \textit{all} fuel limits, traces, and initial states.
    \item \textbf{(run\_vm fuel trace s).(vm\_mu)} — The $\mu$ value of the final state after running \texttt{fuel} steps.
    \item \textbf{s.(vm\_mu) + ledger\_sum (ledger\_entries fuel trace s)} — Initial $\mu$ plus the sum of all paid costs.
    \item \textbf{=} — Exact equality (not just $\geq$).
\end{itemize}

\textbf{Why equality instead of $\geq$?} The single-step theorem uses $\geq$ to allow for zero-cost instructions (though none exist in practice). This multi-step version uses $=$ because the ledger sum \textit{exactly} accounts for all costs paid. If an instruction costs 10, the ledger records 10, and $\mu$ increases by exactly 10.

\textbf{Proof strategy:} The proof proceeds by induction on \texttt{fuel}:
\begin{itemize}
    \item \textbf{Base case (fuel = 0):} \texttt{run\_vm(0, trace, s) = s} (no steps executed). \texttt{ledger\_entries(0, trace, s) = []} (empty ledger). \texttt{s.vm\_mu = s.vm\_mu + 0}. Trivial.
    \item \textbf{Inductive case (fuel = n+1):} Assume the claim holds for \texttt{fuel = n}. Execute one instruction with cost $c$. By \texttt{mu\_conservation\_kernel}, $\mu$ increases by $c$. The ledger records $c$ as the first entry. By induction hypothesis, the remaining $n$ steps add exactly \texttt{ledger\_sum(remaining\_ledger)}. Total: $c +$ \texttt{ledger\_sum(remaining\_ledger)} = \texttt{ledger\_sum(full\_ledger)}.
\end{itemize}

\textbf{Concrete example:} If \texttt{s.vm\_mu = 50} and you execute 3 instructions with costs $[10, 15, 20]$:
\begin{itemize}
    \item \texttt{ledger\_entries(3, trace, s) = [10, 15, 20]}
    \item \texttt{ledger\_sum([10, 15, 20]) = 45}
    \item \texttt{run\_vm(3, trace, s).vm\_mu = 50 + 45 = 95}
\end{itemize}
The corollary guarantees this exact accounting.

\textbf{Physical interpretation:} This is the \textbf{path integral formulation} of thermodynamics. The final entropy (here, $\mu$) is the initial entropy plus the integral (sum) of all irreversible events along the path. Unlike physical systems where heat dissipation can be path-dependent, the Thiele Machine's $\mu$ accounting is exact and path-independent (given a fixed trace).

\textbf{Role in larger proofs:} This corollary is invoked by the No Free Insight theorem. To prove that strengthening a predicate requires $\mu > 0$, the proof shows that the trace must contain revelation events (which cost $\mu$), and invokes this corollary to show the ledger sum is positive.

\begin{proof}
By induction on fuel. Base case: empty ledger, $\mu$ unchanged. Inductive case: by \texttt{mu\_conservation\_kernel}, $\mu$ increases by exactly the instruction cost, which is the head of \texttt{ledger\_entries}.
\end{proof}

\subsection{Irreversibility Bound}

\begin{theorem}[Irreversibility]
\begin{lstlisting}
Theorem vm_irreversible_bits_lower_bound :
  forall fuel trace s,
    irreversible_count fuel trace s <=
      (run_vm fuel trace s).(vm_mu) - s.(vm_mu).
\end{lstlisting}
\end{theorem}

\paragraph{Understanding vm\_irreversible\_bits\_lower\_bound (early reference):}

\textbf{What this proves:} Irreversible bit operations are lower-bounded by $\mu$ growth. Every irreversible event (LASSERT, REVEAL, EMIT) costs at least 1 unit of $\mu$. See full explanation in later instance for complete first-principles breakdown connecting to Landauer's principle.

\textbf{Physical Interpretation}: The $\mu$-ledger growth lower-bounds irreversible bit events—connecting to Landauer's principle.

\section{No Free Insight: The Impossibility Theorem}

% Figure 5: No Free Insight Formal Structure
\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1.8, 
    set/.style={ellipse, draw, minimum width=6.2cm, minimum height=3.6cm},
    arrow/.style={->, >=stealth, thick}
], node distance=2.5cm]
    % Left: Weak predicate (larger set)
    \node[set, fill=blue!10] (weak) at (-3, 0) {};
    \node at (-3, 0) {$P_{\text{weak}}$};
    \node at (-3, -1.5) {\footnotesize Accepts more traces};
    
    % Right: Strong predicate (smaller set)
    \node[set, fill=green!20, minimum width=4.6cm, minimum height=2.5cm] (strong) at (3, 0) {};
    \node at (3, 0) {$P_{\text{strong}}$};
    \node at (3, -1.5) {\footnotesize Accepts fewer traces};
    
    % Arrow showing strengthening
    \draw[->, >=stealth, ultra thick, red, shorten >=2pt, shorten <=2pt] (-0.8, 0) -- (0.8, 0);
    \node at (0, 0.6) {\textbf{Strengthen}};
    \node at (0, -0.5) {\footnotesize $P_{\text{strong}} < P_{\text{weak}}$};
    
    % Cost requirement
    \node[draw, fill=red!20, rounded corners] at (0, -2.5) {\textbf{Requires: structure addition ($\mu > 0$)}};
    
    % Trace box
    \node[draw, fill=yellow!20, rounded corners, text width=10cm, align=center] at (0, -4.2) {
        \textbf{No Free Insight:} To certify a stronger predicate from a weaker one,\\
        the trace \textbf{must} contain a revelation event (REVEAL, LASSERT, LJOIN, EMIT)\\
        which charges $\mu$-cost. There is no backdoor.
    };
\end{tikzpicture}
\caption{No Free Insight: strengthening certification requires explicit, charged structure addition.}
\label{fig:no-free-insight-ch5}
\end{figure}

\paragraph{Understanding Figure \ref{fig:no-free-insight-ch5}:}

\textbf{Similar to Chapter 3 version but in verification context:}

\textbf{Left:} Weak predicate $P_{\text{weak}}$ - accepts many observation sequences (large green circle)

\textbf{Right:} Strong predicate $P_{\text{strong}}$ - accepts fewer sequences (small green circle inside large red circle)

\textbf{Center:} Revelation event required - REVEAL, LASSERT, LJOIN, or EMIT instructions (charges $\mu$-cost)

\textbf{Bottom yellow box:} No Free Insight statement - To certify stronger predicate from weaker one, trace MUST contain revelation event which charges $\mu$-cost. No backdoor.

\textbf{Key insight:} Information gain requires payment - moving from weak to strong certification costs $\mu$. Strengthening predicates is thermodynamically expensive.

\subsection{Receipt Predicates}

\begin{lstlisting}
Definition ReceiptPredicate (A : Type) := list A -> bool.
\end{lstlisting}

\paragraph{Understanding ReceiptPredicate:}

\textbf{What is this?} This defines a \textbf{type alias} for predicates over receipt lists. A \texttt{ReceiptPredicate} is a function that takes a list of observations (receipts) and returns a boolean: true if the predicate accepts the observation sequence, false otherwise.

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{Definition ReceiptPredicate} — Declares a type alias.
    \item \textbf{(A : Type)} — Polymorphic: \texttt{A} can be any type (e.g., \texttt{nat}, \texttt{string}, \texttt{(nat * nat)}).
    \item \textbf{:= list A -> bool} — A \texttt{ReceiptPredicate A} is a function from lists of \texttt{A} to booleans.
\end{itemize}

\textbf{Why predicates?} Predicates capture \textbf{certification policies}. For example:
\begin{itemize}
    \item \textbf{Weak predicate:} ``The receipt list contains at least one non-zero entry.'' (Accepts many sequences.)
    \item \textbf{Strong predicate:} ``The receipt list is exactly $[42]$.'' (Accepts only one sequence.)
\end{itemize}
The No Free Insight theorem proves that moving from a weak to a strong predicate (strengthening) requires paying $\mu$ cost.

\textbf{Concrete example:} Define \texttt{P\_any : ReceiptPredicate nat := fun obs => match obs with [] => false | \_ => true end}. This accepts any non-empty list. Define \texttt{P\_specific : ReceiptPredicate nat := fun obs => obs =? [42]}. This accepts only $[42]$. \texttt{P\_specific} is strictly stronger than \texttt{P\_any}.

\textbf{Role in theorems:} The No Free Insight theorem quantifies over arbitrary \texttt{ReceiptPredicate} types. It states that for \textit{any two predicates} \texttt{P1} and \texttt{P2} with \texttt{P1} strictly stronger than \texttt{P2}, certifying \texttt{P1} from a trace that certifies \texttt{P2} requires $\mu > 0$.

\textbf{Physical interpretation:} Predicates represent \textbf{information content}. A stronger predicate encodes more information (finer-grained constraints). The theorem proves that gaining information costs $\mu$---a computational version of the thermodynamic cost of measurement.

\subsection{Strength Ordering}

\begin{lstlisting}
Definition stronger {A : Type} (P1 P2 : ReceiptPredicate A) : Prop :=
  forall obs, P1 obs = true -> P2 obs = true.

Definition strictly_stronger {A : Type} (P1 P2 : ReceiptPredicate A) : Prop :=
  (P1 <= P2) /\ (exists obs, P1 obs = false /\ P2 obs = true).
\end{lstlisting}

\paragraph{Understanding stronger and strictly\_stronger:}

\textbf{What do these define?} These define the \textbf{strength ordering} on predicates: when one predicate is ``stronger'' (more restrictive) than another. \texttt{P1} is stronger than \texttt{P2} if everything \texttt{P1} accepts is also accepted by \texttt{P2}.

\textbf{Syntax breakdown for stronger:}
\begin{itemize}
    \item \textbf{Definition stronger} — Declares a relation between predicates.
    \item \textbf{\{A : Type\}} — Polymorphic: works for any observation type \texttt{A}.
    \item \textbf{(P1 P2 : ReceiptPredicate A)} — Takes two predicates over the same type.
    \item \textbf{: Prop} — Returns a proposition (a claim that can be proven).
    \item \textbf{forall obs, P1 obs = true -> P2 obs = true} — For \textit{all} observation sequences \texttt{obs}, if \texttt{P1} accepts \texttt{obs}, then \texttt{P2} also accepts \texttt{obs}.
\end{itemize}

\textbf{Intuition:} \texttt{P1} is stronger than \texttt{P2} if \texttt{P1} is ``at least as restrictive'' as \texttt{P2}. Stronger predicates accept fewer sequences. If \texttt{P1} says ``yes,'' then \texttt{P2} must also say ``yes.''

\textbf{Syntax breakdown for strictly\_stronger:}
\begin{itemize}
    \item \textbf{Definition strictly\_stronger} — Declares a \textit{strict} strength ordering.
    \item \textbf{(P1 <= P2)} — \texttt{P1} is stronger than \texttt{P2} (using \texttt{<=} notation, though this is the \textit{reverse} of numerical ordering).
    \item \textbf{/\textbackslash} — Logical AND.
    \item \textbf{exists obs, P1 obs = false /\textbackslash\ P2 obs = true} — There exists at least one observation \texttt{obs} that \texttt{P2} accepts but \texttt{P1} rejects.
\end{itemize}

\textbf{Difference between stronger and strictly\_stronger:} \texttt{stronger} allows \texttt{P1} and \texttt{P2} to be equal (accept exactly the same sequences). \texttt{strictly\_stronger} requires \texttt{P1} to be \textit{genuinely more restrictive}: there must be at least one sequence \texttt{P2} accepts that \texttt{P1} rejects.

\textbf{Concrete example:}
\begin{itemize}
    \item \texttt{P\_any : obs => length(obs) > 0} — Accepts any non-empty list.
    \item \texttt{P\_specific : obs => obs = [42]} — Accepts only $[42]$.
\end{itemize}
\texttt{P\_specific} is \textit{strictly stronger} than \texttt{P\_any} because:
\begin{itemize}
    \item Everything \texttt{P\_specific} accepts ($[42]$), \texttt{P\_any} also accepts (since $[42]$ is non-empty).
    \item \texttt{P\_any} accepts $[1, 2, 3]$, but \texttt{P\_specific} rejects it.
\end{itemize}

\textbf{Role in theorems:} The No Free Insight theorem states that if \texttt{P\_strong} is strictly stronger than \texttt{P\_weak}, then certifying \texttt{P\_strong} from a trace that certifies \texttt{P\_weak} requires $\mu > 0$. The strict ordering ensures genuine information gain.

\subsection{Certification}

\begin{lstlisting}
Definition Certified {A : Type} 
                     (s_final : VMState)
                     (decoder : receipt_decoder A)
                     (P : ReceiptPredicate A)
                     (receipts : Receipts) : Prop :=
  s_final.(vm_err) = false /\ 
  has_supra_cert s_final /\ 
  P (decoder receipts) = true.
\end{lstlisting}

\paragraph{Understanding Certified:}

\textbf{What does this define?} This defines when a final VM state \texttt{s\_final} has \textbf{successfully certified} a predicate \texttt{P} over receipts. Certification requires three conditions: no errors, a valid certificate present, and the predicate accepting the decoded receipts.

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{Definition Certified} — Declares a predicate over VM states and receipts.
    \item \textbf{\{A : Type\}} — Polymorphic: the receipt type \texttt{A} can be anything.
    \item \textbf{(s\_final : VMState)} — The final VM state after execution.
    \item \textbf{(decoder : receipt\_decoder A)} — A function that decodes raw receipts into observations of type \texttt{A}.
    \item \textbf{(P : ReceiptPredicate A)} — The predicate to be certified.
    \item \textbf{(receipts : Receipts)} — The list of receipts emitted during execution.
    \item \textbf{: Prop} — Returns a proposition.
\end{itemize}

\textbf{Three certification conditions:}
\begin{itemize}
    \item \textbf{s\_final.(vm\_err) = false} — The VM did not encounter an error. If \texttt{vm\_err = true}, the execution is invalid and certification fails.
    \item \textbf{has\_supra\_cert s\_final} — The VM has a valid "supra-certificate" (a certificate stronger than classical SAT). This checks the \texttt{csr\_cert\_addr} CSR is non-zero, indicating a certificate was explicitly loaded.
    \item \textbf{P (decoder receipts) = true} — The predicate \texttt{P} accepts the decoded receipts. The \texttt{decoder} translates raw receipt data into structured observations, then \texttt{P} evaluates to \texttt{true}.
\end{itemize}

\textbf{Why all three conditions?} Each condition rules out a failure mode:
\begin{itemize}
    \item Without \texttt{vm\_err = false}, a crashed execution could spuriously satisfy the predicate.
    \item Without \texttt{has\_supra\_cert}, the VM could claim certification without actually proving anything.
    \item Without \texttt{P(...) = true}, the receipts might not match the predicate's requirements.
\end{itemize}

\textbf{Role in theorems:} The No Free Insight theorem assumes \texttt{Certified(s\_final, decoder, P\_strong, receipts)} and proves that reaching this state from \texttt{Certified(..., P\_weak, ...)} requires $\mu > 0$ if \texttt{P\_strong} is strictly stronger than \texttt{P\_weak}.

\subsection{The Main Theorem}

\begin{theorem}[No Free Insight — General Form]
\begin{lstlisting}
Theorem no_free_insight_general :
  forall (trace : Trace) (s_init s_final : VMState) (fuel : nat),
    trace_run fuel trace s_init = Some s_final ->
    s_init.(vm_csrs).(csr_cert_addr) = 0 ->
    has_supra_cert s_final ->
    uses_revelation trace \/
    (exists n m p mu, nth_error trace n = Some (instr_emit m p mu)) \/
    (exists n c1 c2 mu, nth_error trace n = Some (instr_ljoin c1 c2 mu)) \/
    (exists n m f c mu, nth_error trace n = Some (instr_lassert m f c mu)).
\end{lstlisting}
\end{theorem}

\paragraph{Understanding no\_free\_insight\_general (early reference):}

\textbf{What this proves:} If you gain supra-certification (go from no certificate to has\_supra\_cert), the trace MUST contain at least one revelation instruction (REVEAL, EMIT, LJOIN, or LASSERT). There is no backdoor to gain insight without paying $\mu$ cost. See full first-principles explanation in later instance of this theorem.

\begin{proof}
By the revelation requirement. The structure-addition analysis shows that if \texttt{csr\_cert\_addr} starts at 0 and ends non-zero (\texttt{has\_supra\_cert}), some instruction in the trace must have set it.
\end{proof}

\subsection{Strengthening Theorem}

\begin{theorem}[Strengthening Requires Structure]
\begin{lstlisting}
Theorem strengthening_requires_structure_addition :
  forall (A : Type)
         (decoder : receipt_decoder A)
         (P_weak P_strong : ReceiptPredicate A)
         (trace : Receipts)
         (s_init : VMState)
         (fuel : nat),
    strictly_stronger P_strong P_weak ->
    s_init.(vm_csrs).(csr_cert_addr) = 0 ->
    Certified (run_vm fuel trace s_init) decoder P_strong trace ->
    has_structure_addition fuel trace s_init.
\end{lstlisting}
\end{theorem}

\paragraph{Understanding strengthening\_requires\_structure\_addition:}

\textbf{What does this prove?} This proves that \textbf{strengthening a predicate requires structural addition}: if you start with no certificate and end with a certified strong predicate (where ``strong'' means more restrictive than some weaker predicate), the trace must contain structure-adding instructions (revelation events that cost $\mu > 0$).

\textbf{Theorem statement breakdown:}
\begin{itemize}
    \item \textbf{Theorem strengthening\_requires\_structure\_addition} — Names the theorem.
    \item \textbf{forall A decoder P\_weak P\_strong trace s\_init fuel} — Holds for all observation types, decoders, predicates, traces, initial states, and fuel.
    \item \textbf{strictly\_stronger P\_strong P\_weak} — Premise: \texttt{P\_strong} is strictly more restrictive than \texttt{P\_weak}.
    \item \textbf{s\_init.(vm\_csrs).(csr\_cert\_addr) = 0} — Premise: initial state has no certificate.
    \item \textbf{Certified (run\_vm fuel trace s\_init) decoder P\_strong trace} — Premise: the final state certifies \texttt{P\_strong}.
    \item \textbf{has\_structure\_addition fuel trace s\_init} — Conclusion: the trace contains at least one structure-adding instruction (REVEAL, EMIT, LJOIN, LASSERT).
\end{itemize}

\textbf{Why ``structure addition''?} The predicate \texttt{has\_structure\_addition} checks for instructions that modify \texttt{csr\_cert\_addr} or add axioms to modules. These are exactly the instructions that add logical structure (constraints, observations, certificates) to the system.

\textbf{Connection to no\_free\_insight\_general:} This theorem is a direct consequence of \texttt{no\_free\_insight\_general}:
\begin{enumerate}
    \item Unfold \texttt{Certified} to get \texttt{has\_supra\_cert (run\_vm fuel trace s\_init)}.
    \item By \texttt{no\_free\_insight\_general}, the trace contains a revelation-type instruction.
    \item Revelation-type instructions are structure-adding, so \texttt{has\_structure\_addition} holds.
\end{enumerate}

\textbf{Physical interpretation:} This is the precise formalization of ``no free insight.'' Moving from a weak predicate (less information) to a strong predicate (more information) requires adding structure, which costs $\mu$. The theorem proves there's no way to gain information without paying thermodynamic cost.

\textbf{Concrete example:} Suppose \texttt{P\_weak} accepts any non-empty receipt list, and \texttt{P\_strong} accepts only $[42]$. If you start with no certificate and end with certification of \texttt{P\_strong}, the trace must contain at least one EMIT (to emit 42), LASSERT (to prove 42 satisfies constraints), or similar revelation. You can't magically certify $[42]$ without explicitly producing 42.

\begin{proof}
\begin{enumerate}
    \item Unfold \texttt{Certified} to get \texttt{has\_supra\_cert}
    \texttt{(run\_vm fuel trace s\_init)}
    \item Apply \texttt{supra\_cert\_implies\_structure\_addition\_in\_run}
    \item The key lemma: reaching \texttt{has\_supra\_cert} from \texttt{csr\_cert\_addr = 0} requires an explicit cert-setter instruction
\end{enumerate}
\end{proof}

\section{Revelation Requirement: Supra-Quantum Certification}

\begin{theorem}[Nonlocal Correlation Requires Revelation]
\begin{lstlisting}
Theorem nonlocal_correlation_requires_revelation :
  forall (trace : Trace) (s_init s_final : VMState) (fuel : nat),
    trace_run fuel trace s_init = Some s_final ->
    s_init.(vm_csrs).(csr_cert_addr) = 0 ->
    has_supra_cert s_final ->
    uses_revelation trace \/
    (exists n m p mu, nth_error trace n = Some (instr_emit m p mu)) \/
    (exists n c1 c2 mu, nth_error trace n = Some (instr_ljoin c1 c2 mu)) \/
    (exists n m f c mu, nth_error trace n = Some (instr_lassert m f c mu)).
\end{lstlisting}
\end{theorem}

\paragraph{Understanding nonlocal\_correlation\_requires\_revelation:}

\textbf{What does this prove?} This proves that \textbf{supra-quantum correlations} (correlations stronger than quantum mechanics allows, achieved via partition-native computing) require explicit revelation events. You cannot produce nonlocal correlations (e.g., CHSH violation > 2$\sqrt{2}$) without paying $\mu$ cost.

\textbf{Theorem statement:} This is \textit{identical} to \texttt{no\_free\_insight\_general}. The difference is \textit{interpretation}: here, the theorem is framed in terms of physical correlations (CHSH experiments, Bell tests) rather than abstract predicate strengthening.

\textbf{Why this interpretation?} In the Thiele Machine:
\begin{itemize}
    \item \textbf{Supra-quantum correlations} are achieved by partitioning a problem, solving each partition with classical tools (SAT solvers, SMT solvers), then merging results.
    \item The \texttt{has\_supra\_cert} predicate checks that the VM has a valid certificate stronger than classical bounds.
    \item To produce such a certificate, the VM must execute revelation instructions (LASSERT with SAT proofs, REVEAL to make partition results observable, EMIT to record measurements).
\end{itemize}

\textbf{Physical context:} Classical physics allows CHSH values up to 2. Quantum mechanics allows up to $2\sqrt{2} \approx 2.828$. The Thiele Machine can achieve 4 (the algebraic maximum) by constructing partition structures that enforce perfect correlation. This theorem proves that reaching such correlations requires explicit structure-building instructions, each costing $\mu$.

\textbf{Why ``nonlocal''?} The correlations are \textit{nonlocal} in the sense that they involve multiple spatially separated partitions (modules). The no-signaling theorem (earlier) proves that operations on one partition don't affect others. This theorem proves that to \textit{correlate} partitions (make them jointly produce supra-quantum outcomes), you must use revelation to make their states mutually observable, which costs $\mu$.

\textbf{Concrete example (CHSH):} To produce CHSH = 4:
\begin{enumerate}
    \item Create two partitions (Alice and Bob) with PNEW (costs $\mu$).
    \item Add axioms enforcing perfect correlation via LASSERT (costs $\mu$).
    \item Execute measurement instructions (costs $\mu$).
    \item Emit results via EMIT (costs $\mu$).
\end{enumerate}
The theorem guarantees you can't skip steps 2-4 and still certify the correlation.

\textbf{Interpretation}: To achieve supra-quantum certification, you must explicitly pay for it through a revelation-type instruction. There is no backdoor.

\section{Proof Summary}

At the end of the verification campaign, the active proof tree contains no admits and no axioms beyond foundational logic. The result is a closed, machine-checked account of the model’s physics, accounting rules, and impossibility results. Every theorem in this chapter can be reconstructed from the definitions and lemmas above.

\section{Falsifiability}

Every theorem includes a falsifier specification:

\begin{lstlisting}
(** FALSIFIER: Exhibit a system satisfying A1-A4 where:
    - Two predicates P_weak, P_strong with P_strong strictly stronger
    - A trace certifying P_strong
    - No revelation events in the trace
   This would falsify the No Free Insight theorem. **)
\end{lstlisting}

\paragraph{Understanding the Falsifier Specification:}

\textbf{What is this?} This is a \textbf{falsifiability specification}: a precise description of what evidence would \textit{disprove} the No Free Insight theorem. Science demands falsifiable claims---this comment makes the falsification criteria explicit.

\textbf{Syntax breakdown:}
\begin{itemize}
    \item \textbf{(** ... **)} — Coq comment syntax (multi-line comment).
    \item \textbf{FALSIFIER:} — Keyword marking this as a falsification specification.
    \item \textbf{Exhibit a system satisfying A1-A4} — The falsifying system must satisfy the theorem's assumptions (axioms A1-A4, which define the Thiele Machine's operational semantics).
    \item \textbf{Two predicates P\_weak, P\_strong with P\_strong strictly stronger} — The predicates must satisfy the strength ordering (as defined in \texttt{strictly\_stronger}).
    \item \textbf{A trace certifying P\_strong} — The trace must produce \texttt{Certified(..., P\_strong, ...)}.
    \item \textbf{No revelation events in the trace} — The trace must \textit{not} contain REVEAL, EMIT, LJOIN, or LASSERT instructions.
\end{itemize}

\textbf{Why include this?} This makes the theorem \textit{falsifiable} in Popper's sense. If someone claims to have a counterexample, this specification defines exactly what they must provide. Without such a specification, the theorem would be unfalsifiable (and therefore unscientific).

\textbf{Can this falsifier be satisfied?} No---that's the point. The No Free Insight theorem \textit{proves} that no such system exists. If someone exhibited a system satisfying these conditions, they would have found a bug in the Coq proof, invalidated the theorem, or discovered a flaw in the Thiele Machine's axioms.

\textbf{Role in scientific rigor:} Every major theorem in the thesis includes such a falsifier specification. This follows the principle that \textit{proof} and \textit{falsifiability} are dual: a proof shows no counterexample exists, and a falsifier specification defines what a counterexample would look like.

\textbf{Concrete example:} To falsify the theorem, you'd need to show:
\begin{enumerate}
    \item A weak predicate \texttt{P\_weak} (e.g., ``accepts any non-empty list'').
    \item A strong predicate \texttt{P\_strong} (e.g., ``accepts only $[42]$'').
    \item A Thiele Machine trace that starts with \texttt{csr\_cert\_addr = 0}, ends with \texttt{Certified(..., P\_strong, ...)}, but contains \textit{no} REVEAL, EMIT, LJOIN, or LASSERT instructions.
\end{enumerate}
The theorem proves this is impossible: you cannot certify $[42]$ without explicitly producing it via a revelation event.
    - Two predicates P_weak, P_strong with P_strong < P_weak
    - A trace tr certifies P_strong
    - tr contains NO revelation event
    *)

If anyone can produce such a counterexample, the theorem is false. The proofs establish that no such counterexample exists within the Thiele Machine model.

\section{Summary}

% Figure 6: Chapter 5 Summary
\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1.8, 
    theorem/.style={rectangle, draw, fill=green!20, minimum width=7.2cm, minimum height=2.2cm, align=center, rounded corners},
    property/.style={rectangle, draw, fill=blue!10, minimum width=6.2cm, minimum height=1.6cm, align=center},
    arrow/.style={->, >=stealth, thick}
], node distance=2.5cm]
    % Central: Zero-Admit Standard
    \node[draw, fill=red!30, minimum width=9.0cm, minimum height=1.8cm, rounded corners, align=center, text width=3.5cm] (zero) at (0, 0) {\textbf{Zero-Admit Standard}\\206 Proofs, 0 Axioms};
    
    % Four theorem boxes around it
    \node[theorem, align=center, text width=3.5cm] (nosig) at (-4, 2.5) {\textbf{No-Signaling}\\Bell locality analog};
    \node[theorem, align=center, text width=3.5cm] (mucons) at (4, 2.5) {\textbf{$\mu$-Conservation}\\Monotonic ledger};
    \node[theorem, align=center, text width=3.5cm] (nofi) at (-4, -2.5) {\textbf{No Free Insight}\\Impossibility theorem};
    \node[theorem, align=center, text width=3.5cm] (gauge) at (4, -2.5) {\textbf{Gauge Invariance}\\Noether's theorem};
    
    % Arrows to center
    \draw[arrow, dashed, shorten >=2pt, shorten <=2pt] (nosig) -- (zero);
    \draw[arrow, dashed, shorten >=2pt, shorten <=2pt] (mucons) -- (zero);
    \draw[arrow, dashed, shorten >=2pt, shorten <=2pt] (nofi) -- (zero);
    \draw[arrow, dashed, shorten >=2pt, shorten <=2pt] (gauge) -- (zero);
    
    % Bottom: Inquisitor
    \node[draw, fill=purple!20, minimum width=14.4cm, minimum height=1.6cm, rounded corners] at (0, -4.5) {\textbf{Inquisitor} enforces standard via CI (25+ rule categories)};
    
    % Title
    \node at (0, 4) {\textbf{Chapter 5: Verification Results}};
\end{tikzpicture}
\caption{Chapter summary: four key theorems proven under zero-admit standard, enforced by Inquisitor.}
\label{fig:ch5-summary}
\end{figure}

\paragraph{Understanding Figure \ref{fig:ch5-summary}:}

\textbf{Four theorem boxes (top):}
\begin{enumerate}
    \item \textbf{No-Signaling (blue):} Locality - operations on one module don't affect others
    \item \textbf{Gauge Invariance (green):} Partition structure invariant under $\mu$-shifts (Noether)
    \item \textbf{$\mu$-Conservation (orange):} Ledger monotonically non-decreasing (Second Law)
    \item \textbf{No Free Insight (red):} Strengthening certification requires $\mu > 0$ (impossibility)
\end{enumerate}

\textbf{Center (yellow box):} Zero-Admit Standard - No Admitted, No admit., No Axiom, No vacuous statements

\textbf{Arrows:} All four theorems point down to zero-admit standard - enforcement foundation

\textbf{Bottom (purple box):} Inquisitor enforces standard via CI (25+ rule categories) - automated verification

\textbf{Key insight:} Four fundamental theorems (locality, gauge invariance, conservation, impossibility) all proven under strictest standard - 0 HIGH findings, CI-enforced.

The formal verification campaign establishes:
\begin{enumerate}
    \item \textbf{Locality}: Operations on one module cannot affect observables of unrelated modules
    \item \textbf{Conservation}: The $\mu$-ledger is monotonic and bounds irreversible operations
    \item \textbf{Impossibility}: Strengthening certification requires explicit, charged structure addition
    \item \textbf{Completeness}: Zero admits, zero axioms—all proofs are machine-checked
\end{enumerate}

These are not aspirational properties but proven invariants of the system.
