# Thiele Machine Audit Summary

This report summarizes the automated audit and falsification experiments performed in-repo. All commands below were run inside the repository and results saved to `artifacts/`.

## Actions performed
- Ran Python verification harness: `tools/verify_shor.py` (period finding + reduction).
- Implemented and ran empirical benchmarks:
  - `scripts/benchmarks/period_scaling.py` -> `artifacts/period_scaling.csv`, `artifacts/period_scaling.png`
  - `scripts/benchmarks/factor_compare.py` -> `artifacts/factor_compare.csv`
  - Base scan for `N=3233` -> `artifacts/period_3233_bases.csv`, `artifacts/period_3233_bases.png`
- Optimized `thielecpu/shor_oracle.py` to compute residues incrementally and only add Z3 constraints for computed residues (reduces O(n) setup when period << n).
- Re-ran benchmarks and recorded improved wall times for large-period cases.
- Performed a resource extrapolation to RSA-2048 and saved results to `artifacts/rsa_extrapolation.txt`.
- Collected any Coq `Admitted`/`admit.`/`Axiom` occurrences and saved to `artifacts/coq_admits.txt`.

## Key findings

- Correctness: `find_period_with_claims` returns valid periods for the tested cases (verified by `tools/verify_shor.py`).
- μ-cost and solver queries remain small (≈6–8) for the tested examples.
- Runtime behavior: wall time is dominated by residue enumeration. Measured wall time correlates linearly with number of residues computed.
- Optimization: computing residues incrementally (stop at first stabiliser) reduced the residues computed for `N=3233` from 6467 → 781 and reduced wall time from ~5–12s to ~1.34s in this environment.
- Factoring capability: Thiele reduction produced factors for many small N; classical baselines (trial division, Pollard's Rho) factor these small N orders of magnitude faster in wall time on a CPU, though Thiele reports low μ-cost.
- RSA-2048 feasibility: extrapolation (simple linear model) indicates astronomical runtime if the period scales with N; see `artifacts/rsa_extrapolation.txt` for detailed numbers. The measured alpha was ~1.67e-3 s per residue; worst-case extrapolation to N≈2^2048 yields log10(years) ≈ 606 (i.e., inconceivably large).
- Coq admits/axioms: automated scans and the repo's verification scripts indicate the active compiled tree reports zero `Axiom`/`Admitted` in the built modules; documentation and audit artifacts reference admitted items in development comments and in artifacts (see `artifacts/coq_admits.txt`).

## Files generated
- `artifacts/period_scaling.csv`, `artifacts/period_scaling.png`
- `artifacts/factor_compare.csv`
- `artifacts/period_3233_bases.csv`, `artifacts/period_3233_bases.png`
- `artifacts/rsa_extrapolation.txt`
- `artifacts/coq_admits.txt`
- `artifacts/audit_report.md` (this file)

## Recommendations

1. For the thesis claim that partition-native computing replaces quantum period finding asymptotically, provide an explicit complexity-reduction argument that avoids residue enumeration or otherwise reduces the number of modular exponentiations below O(n). Current implementation still requires enumerating residues up to the discovered period; unless the period is guaranteed to be tiny (proof obligation), the approach does not asymptotically beat classical methods.
2. Make μ-cost mapping explicit: show how low μ-cost translates into wall-clock or parallelizable work that is implementable on real hardware for large N.
3. Continue the Coq hygiene work: ensure the `Inquisitor` checks remain in CI and address any development comments listing admitted lemmas (these appear in comments or artifacts but not in compiled modules per current checks).
4. If claiming practical RSA-2048 breaking, provide a detailed resource model and demonstration on larger but still feasible key sizes (e.g., 64- to 256-bit) showing extrapolation is valid. Do not attempt real-world key attacks without proper authorization and explicit scope.

## Repro commands
Run the key scripts used in this audit (from repository root):

```bash
python3 tools/verify_shor.py
python3 scripts/benchmarks/period_scaling.py
python3 scripts/benchmarks/factor_compare.py
```

## Next steps I can take (pick):
- Expand extrapolation to include solver-cost modeling and parallelism assumptions.
- Implement a streaming Z3 interface to avoid adding many constraints at once (further reduce memory/time peaks).
- Produce a formal mapping report between specific Coq lemmas and Python functions (line-level cross-reference).

---
Report generated by automated audit steps; all generated artifacts are in `artifacts/`.
