diff --git a/scripts/run_bug_hunter.py b/scripts/run_bug_hunter.py
new file mode 100755
index 0000000000000000000000000000000000000000..25f313b9d5ec8848074b74351154ac66d470f93f
--- /dev/null
+++ b/scripts/run_bug_hunter.py
@@ -0,0 +1,52 @@
+#!/usr/bin/env python3
+"""Command line entry point for the Thiele bug hunter."""
+
+from __future__ import annotations
+
+import argparse
+from pathlib import Path
+
+from tools.bughunter import BugHunter, DEFAULT_RULES
+
+
+def parse_args() -> argparse.Namespace:
+    parser = argparse.ArgumentParser(description="Run the Thiele Machine bug hunting framework")
+    parser.add_argument(
+        "repo",
+        type=Path,
+        help="Path to the repository to analyse",
+    )
+    parser.add_argument(
+        "--output",
+        type=Path,
+        default=Path("results/bughunter_report.json"),
+        help="Where to write the JSON report (default: results/bughunter_report.json)",
+    )
+    parser.add_argument(
+        "--rules",
+        nargs="*",
+        default=None,
+        help="Subset of rule names to run; defaults to all",
+    )
+    return parser.parse_args()
+
+
+def main() -> None:
+    args = parse_args()
+    repo = args.repo
+    if args.rules:
+        selected = [rule for rule in DEFAULT_RULES if rule.name in set(args.rules)]
+        if not selected:
+            raise SystemExit("No matching rules selected")
+    else:
+        selected = DEFAULT_RULES
+
+    hunter = BugHunter(repo, rules=selected)
+    report = hunter.run()
+    output_path = hunter.save_report(args.output)
+    print(f"Analysed {report.scanned_files} files; findings: {len(report.findings)}")
+    print(f"Report written to {output_path}")
+
+
+if __name__ == "__main__":
+    main()
diff --git a/tests/data/vulnerable_repo/insecure.py b/tests/data/vulnerable_repo/insecure.py
new file mode 100644
index 0000000000000000000000000000000000000000..bc3b936c874b6bd05506850ed4c7af8240a906a6
--- /dev/null
+++ b/tests/data/vulnerable_repo/insecure.py
@@ -0,0 +1,21 @@
+import os
+import subprocess
+import yaml
+
+
+def run_user_command(cmd):
+    # Critical bug: directly passes user input into the shell
+    subprocess.run(cmd, shell=True)
+
+
+def dangerous_eval(user_input):
+    return eval(user_input)
+
+
+def load_config(data):
+    # yaml.load without safe loader allows arbitrary object construction
+    return yaml.load(data)
+
+
+def legacy_os_call(cmd):
+    os.system(cmd)
diff --git a/tests/test_bughunter.py b/tests/test_bughunter.py
new file mode 100644
index 0000000000000000000000000000000000000000..937f5a3803b251a47416ea4125262c44f296896a
--- /dev/null
+++ b/tests/test_bughunter.py
@@ -0,0 +1,37 @@
+from __future__ import annotations
+
+from pathlib import Path
+import sys
+
+ROOT = Path(__file__).resolve().parents[1]
+if str(ROOT) not in sys.path:
+    sys.path.insert(0, str(ROOT))
+
+from tools.bughunter import BugHunter, DEFAULT_RULES
+
+
+def test_bug_hunter_detects_critical_patterns(tmp_path):
+    repo = Path(__file__).parent / "data" / "vulnerable_repo"
+    hunter = BugHunter(repo)
+    report = hunter.run()
+
+    assert report.scanned_files == 1
+    assert {rule for rule in report.executed_rules} == {r.name for r in DEFAULT_RULES}
+
+    finding_rules = {finding.rule for finding in report.findings}
+    assert {"subprocess-shell", "eval-exec", "yaml-unsafe-load"}.issubset(finding_rules)
+
+    # os.system should also trigger the subprocess rule (duplicate severity check)
+    shell_findings = [f for f in report.findings if f.rule == "subprocess-shell"]
+    assert any("shell=True" in f.message or "os.system" in f.message for f in shell_findings)
+
+    for finding in report.findings:
+        assert finding.remediation, "Each finding must include a remediation hint"
+        assert finding.line > 0
+
+    # Ensure report can be serialised to JSON and written to disk
+    output_path = tmp_path / "bughunter_report.json"
+    hunter.save_report(output_path)
+    saved = output_path.read_text()
+    assert "subprocess-shell" in saved
+    assert "eval-exec" in saved
diff --git a/tools/bughunter/__init__.py b/tools/bughunter/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..b7f7f33ea6ef2e5881199e21ea2a0de317944384
--- /dev/null
+++ b/tools/bughunter/__init__.py
@@ -0,0 +1,16 @@
+"""Automated bug hunting framework built on the Thiele VM."""
+
+from .framework import BugHunter, BugHunterReport
+from .rules import DEFAULT_RULES, SubprocessShellRule, EvalExecRule, YamlUnsafeLoadRule
+from .types import Finding, LogEntry
+
+__all__ = [
+    "BugHunter",
+    "BugHunterReport",
+    "Finding",
+    "LogEntry",
+    "DEFAULT_RULES",
+    "SubprocessShellRule",
+    "EvalExecRule",
+    "YamlUnsafeLoadRule",
+]
diff --git a/tools/bughunter/framework.py b/tools/bughunter/framework.py
new file mode 100644
index 0000000000000000000000000000000000000000..0195b0e1d96ebd45323a867a1c82f9f1217fdc8a
--- /dev/null
+++ b/tools/bughunter/framework.py
@@ -0,0 +1,190 @@
+"""Automation harness for running bug hunts inside the Thiele VM."""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime, timezone
+from pathlib import Path
+from typing import Iterable, List, Optional, Sequence
+import json
+import ast
+
+from thielecpu.vm import VM
+from thielecpu.state import State
+
+from .rules import DEFAULT_RULES, Rule
+from .types import Finding, LogEntry
+
+
+@dataclass
+class BugHunterReport:
+    """Aggregated results from a bug hunt."""
+
+    repo: Path
+    findings: List[Finding]
+    logs: List[LogEntry]
+    scanned_files: int
+    executed_rules: Sequence[str]
+    timestamp: str
+
+    def to_dict(self) -> dict:
+        return {
+            "repo": str(self.repo),
+            "timestamp": self.timestamp,
+            "scanned_files": self.scanned_files,
+            "executed_rules": list(self.executed_rules),
+            "findings": [f.to_dict(self.repo) for f in self.findings],
+            "logs": [log.to_dict() for log in self.logs],
+        }
+
+    def to_json(self, *, indent: int = 2) -> str:
+        return json.dumps(self.to_dict(), indent=indent)
+
+
+class BugHunter:
+    """Coordinates rule execution and logging through the Thiele VM."""
+
+    _EXCLUDED_DIRS = {".git", "__pycache__", "venv", ".venv", "node_modules", "dist", "build"}
+
+    def __init__(
+        self,
+        repo: Path,
+        *,
+        rules: Optional[Sequence[Rule]] = None,
+        vm: Optional[VM] = None,
+    ) -> None:
+        self.repo = repo.resolve()
+        self.rules: Sequence[Rule] = rules if rules is not None else DEFAULT_RULES
+        self.vm = vm or VM(State())
+        self.vm.state.log = self._log  # type: ignore[attr-defined]
+        self.vm.python_globals["SESSION"] = self
+        self._logs: List[LogEntry] = []
+        self._findings: List[Finding] = []
+        self._latest_report: Optional[BugHunterReport] = None
+
+    # ------------------------------------------------------------------
+    # Public API
+    # ------------------------------------------------------------------
+    def run(self) -> BugHunterReport:
+        """Execute all rules and return a structured report."""
+
+        if not self.repo.exists():
+            raise FileNotFoundError(f"Repository path {self.repo} does not exist")
+
+        self._reset()
+        self.vm.execute_python("self.state.log('PNEW: Initialising Thiele bug hunter session')")
+        self.vm.execute_python("SESSION._run_analysis()")
+        if self._latest_report is None:
+            raise RuntimeError("Bug hunt did not produce a report")
+        return self._latest_report
+
+    def save_report(self, destination: Path, *, indent: int = 2) -> Path:
+        """Persist the most recent report to ``destination``."""
+
+        if self._latest_report is None:
+            raise RuntimeError("No report available; run the bug hunter first")
+        destination = destination.resolve()
+        destination.parent.mkdir(parents=True, exist_ok=True)
+        destination.write_text(self._latest_report.to_json(indent=indent))
+        return destination
+
+    # ------------------------------------------------------------------
+    # Internal execution helpers (invoked inside the VM sandbox)
+    # ------------------------------------------------------------------
+    def _run_analysis(self) -> None:
+        files = list(self._collect_python_files())
+        self.vm.state.log(f"LINFER: Scanning {len(files)} Python files")
+        for path in files:
+            rel = self._relative(path)
+            self.vm.state.log(f"PEXAMINE: {rel}")
+            source = self._safe_read(path)
+            if source is None:
+                continue
+            try:
+                tree = ast.parse(source, filename=str(path))
+            except SyntaxError as exc:
+                self._log(
+                    f"LASSERT: Failed to parse {rel}: {exc}",
+                    severity="warning",
+                )
+                continue
+            for rule in self.rules:
+                try:
+                    for finding in rule.analyze(tree, path, source):
+                        self._record_finding(finding)
+                except Exception as exc:  # pragma: no cover - defensive
+                    self._log(
+                        f"LASSERT: Rule {rule.name} crashed on {rel}: {exc}",
+                        severity="error",
+                    )
+        timestamp = self._now().isoformat()
+        self._latest_report = BugHunterReport(
+            repo=self.repo,
+            findings=list(self._findings),
+            logs=list(self._logs),
+            scanned_files=len(files),
+            executed_rules=[rule.name for rule in self.rules],
+            timestamp=timestamp,
+        )
+        self.vm.state.log(
+            f"LDEDUCE: Analysis complete with {len(self._findings)} findings",
+        )
+
+    # ------------------------------------------------------------------
+    # Utility methods
+    # ------------------------------------------------------------------
+    def _reset(self) -> None:
+        self._logs.clear()
+        self._findings.clear()
+        self._latest_report = None
+
+    def _log(self, message: str, *, severity: str = "INFO") -> None:
+        entry = LogEntry(
+            timestamp=self._now().isoformat(),
+            message=message,
+            severity=severity.upper(),
+        )
+        self._logs.append(entry)
+
+    def _record_finding(self, finding: Finding) -> None:
+        self._findings.append(finding)
+        rel = self._relative(finding.file)
+        self._log(
+            f"LDEDUCE: {finding.rule} -> {rel}:{finding.line}",
+        )
+
+    def _collect_python_files(self) -> Iterable[Path]:
+        for path in self.repo.rglob("*.py"):
+            if any(part in self._EXCLUDED_DIRS for part in path.parts):
+                continue
+            if path.is_file():
+                yield path
+
+    def _safe_read(self, path: Path) -> Optional[str]:
+        try:
+            return path.read_text(encoding="utf-8")
+        except UnicodeDecodeError:
+            self._log(
+                f"LASSERT: Skipping non-UTF8 file {self._relative(path)}",
+                severity="warning",
+            )
+        except OSError as exc:
+            self._log(
+                f"LASSERT: Failed to read {self._relative(path)}: {exc}",
+                severity="error",
+            )
+        return None
+
+    def _relative(self, path: Path) -> str:
+        try:
+            return str(path.relative_to(self.repo))
+        except ValueError:
+            return str(path)
+
+    def _now(self) -> datetime:
+        """Return a timezone-aware timestamp for logging."""
+
+        return datetime.now(timezone.utc).replace(microsecond=0)
+
+
+__all__ = ["BugHunter", "BugHunterReport"]
diff --git a/tools/bughunter/rules.py b/tools/bughunter/rules.py
new file mode 100644
index 0000000000000000000000000000000000000000..d3ff54f0124c23cd81b050003c2f06c74c6f0023
--- /dev/null
+++ b/tools/bughunter/rules.py
@@ -0,0 +1,185 @@
+"""Security rules enforced by the Thiele bug hunter."""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import ast
+from pathlib import Path
+from typing import Iterable, List
+
+from .types import Finding
+
+
+@dataclass
+class Rule:
+    """Base class for bug hunting rules."""
+
+    name: str
+    description: str
+    severity: str
+
+    def analyze(self, tree: ast.AST, path: Path, source: str) -> List[Finding]:
+        raise NotImplementedError
+
+
+def _call_name(node: ast.Call) -> str | None:
+    target = node.func
+    if isinstance(target, ast.Name):
+        return target.id
+    if isinstance(target, ast.Attribute):
+        parts: List[str] = []
+        while isinstance(target, ast.Attribute):
+            parts.append(target.attr)
+            target = target.value
+        if isinstance(target, ast.Name):
+            parts.append(target.id)
+            return ".".join(reversed(parts))
+    return None
+
+
+class SubprocessShellRule(Rule):
+    """Detect shell-based command execution that enables injection."""
+
+    def __init__(self) -> None:
+        super().__init__(
+            name="subprocess-shell",
+            description="Detects subprocess calls that enable shell injection via shell=True or os.system.",
+            severity="critical",
+        )
+
+    def analyze(self, tree: ast.AST, path: Path, source: str) -> List[Finding]:
+        findings: List[Finding] = []
+        lines = source.splitlines()
+        for node in ast.walk(tree):
+            if not isinstance(node, ast.Call):
+                continue
+            call_name = _call_name(node)
+            if call_name in {"os.system", "os.popen", "os.popen2", "os.popen3", "os.popen4"}:
+                findings.append(
+                    Finding(
+                        rule=self.name,
+                        severity=self.severity,
+                        file=path,
+                        line=getattr(node, "lineno", 1),
+                        message=f"Call to {call_name} executes a shell command without sanitisation.",
+                        remediation="Use subprocess.run with an argument list and shell=False, or sanitise the input command.",
+                        evidence=lines[getattr(node, "lineno", 1) - 1].strip() if lines else None,
+                    )
+                )
+                continue
+            if call_name and call_name.startswith("subprocess."):
+                for kw in node.keywords:
+                    if kw.arg == "shell" and isinstance(kw.value, ast.Constant) and kw.value.value is True:
+                        findings.append(
+                            Finding(
+                                rule=self.name,
+                                severity=self.severity,
+                                file=path,
+                                line=getattr(node, "lineno", 1),
+                                message=f"{call_name} invoked with shell=True enables shell injection.",
+                                remediation="Invoke subprocess with shell=False and pass arguments as a list, or escape user input strictly.",
+                                evidence=lines[getattr(node, "lineno", 1) - 1].strip() if lines else None,
+                            )
+                        )
+        return findings
+
+
+class EvalExecRule(Rule):
+    """Detect use of eval/exec on potentially attacker-controlled data."""
+
+    def __init__(self) -> None:
+        super().__init__(
+            name="eval-exec",
+            description="Detects use of eval/exec which can lead to arbitrary code execution.",
+            severity="critical",
+        )
+
+    def analyze(self, tree: ast.AST, path: Path, source: str) -> List[Finding]:
+        findings: List[Finding] = []
+        lines = source.splitlines()
+        for node in ast.walk(tree):
+            if isinstance(node, ast.Call):
+                call_name = _call_name(node)
+                if call_name in {"eval", "exec"}:
+                    findings.append(
+                        Finding(
+                            rule=self.name,
+                            severity=self.severity,
+                            file=path,
+                            line=getattr(node, "lineno", 1),
+                            message=f"Use of {call_name} executes dynamically supplied Python code.",
+                            remediation="Avoid eval/exec. For expressions use ast.literal_eval; otherwise implement explicit parsing or allow-listed operations.",
+                            evidence=lines[getattr(node, "lineno", 1) - 1].strip() if lines else None,
+                        )
+                    )
+        return findings
+
+
+class YamlUnsafeLoadRule(Rule):
+    """Detect unsafe yaml.load usages without a safe Loader."""
+
+    _SAFE_LOADERS = {
+        "SafeLoader",
+        "CSafeLoader",
+        "FullLoader",
+        "SafeConstructor",
+    }
+
+    def __init__(self) -> None:
+        super().__init__(
+            name="yaml-unsafe-load",
+            description="Detects yaml.load without an explicit safe Loader.",
+            severity="high",
+        )
+
+    def analyze(self, tree: ast.AST, path: Path, source: str) -> List[Finding]:
+        findings: List[Finding] = []
+        lines = source.splitlines()
+        for node in ast.walk(tree):
+            if not isinstance(node, ast.Call):
+                continue
+            call_name = _call_name(node)
+            if call_name != "yaml.load":
+                continue
+            safe = False
+            for kw in node.keywords:
+                if kw.arg == "Loader":
+                    if isinstance(kw.value, ast.Attribute):
+                        loader_name = f"{getattr(kw.value.value, 'id', '')}.{kw.value.attr}" if isinstance(kw.value.value, ast.Name) else kw.value.attr
+                    elif isinstance(kw.value, ast.Name):
+                        loader_name = kw.value.id
+                    elif isinstance(kw.value, ast.Constant):
+                        loader_name = str(kw.value.value)
+                    else:
+                        loader_name = None
+                    if loader_name and any(loader_name.endswith(loader) for loader in self._SAFE_LOADERS):
+                        safe = True
+                        break
+            if not safe:
+                findings.append(
+                    Finding(
+                        rule=self.name,
+                        severity=self.severity,
+                        file=path,
+                        line=getattr(node, "lineno", 1),
+                        message="yaml.load without a safe Loader deserialises arbitrary objects.",
+                        remediation="Switch to yaml.safe_load or pass Loader=yaml.SafeLoader explicitly.",
+                        evidence=lines[getattr(node, "lineno", 1) - 1].strip() if lines else None,
+                    )
+                )
+        return findings
+
+
+DEFAULT_RULES: List[Rule] = [
+    SubprocessShellRule(),
+    EvalExecRule(),
+    YamlUnsafeLoadRule(),
+]
+
+__all__ = [
+    "Rule",
+    "SubprocessShellRule",
+    "EvalExecRule",
+    "YamlUnsafeLoadRule",
+    "DEFAULT_RULES",
+]
diff --git a/tools/bughunter/types.py b/tools/bughunter/types.py
new file mode 100644
index 0000000000000000000000000000000000000000..58cb796fc3a622c4e9dd0a6116ff82fa80a5670e
--- /dev/null
+++ b/tools/bughunter/types.py
@@ -0,0 +1,53 @@
+"""Shared dataclasses for the bug hunter framework."""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+
+@dataclass
+class LogEntry:
+    """Structured log emitted by the bug hunter via the Thiele VM."""
+
+    timestamp: str
+    message: str
+    severity: str = "INFO"
+
+    def to_dict(self) -> Dict[str, Any]:
+        return {
+            "timestamp": self.timestamp,
+            "severity": self.severity,
+            "message": self.message,
+        }
+
+
+@dataclass
+class Finding:
+    """Represents a security finding uncovered during analysis."""
+
+    rule: str
+    severity: str
+    file: Path
+    line: int
+    message: str
+    remediation: str
+    evidence: Optional[str] = None
+
+    def to_dict(self, repo_root: Path) -> Dict[str, Any]:
+        try:
+            rel_path = str(self.file.relative_to(repo_root))
+        except ValueError:
+            rel_path = str(self.file)
+        payload: Dict[str, Any] = {
+            "rule": self.rule,
+            "severity": self.severity,
+            "file": rel_path,
+            "line": self.line,
+            "message": self.message,
+            "remediation": self.remediation,
+        }
+        if self.evidence is not None:
+            payload["evidence"] = self.evidence
+        return payload
